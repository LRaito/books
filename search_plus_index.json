{"./":{"url":"./","title":"简介","keywords":"","body":"简介简单分享一些技术文档Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-24 "},"doc_gitbook/":{"url":"doc_gitbook/","title":"GitBook","keywords":"","body":"简介GitBook 是一个使用 Git 和 Markdown 来构建书籍的工具。它可以将你的书输出很多格式：PDF，ePub，mobi，或者输出为静态网页。GitBook工具链是开源并且完全免费的，它的源码可以在 GitHub 上获取。Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-24 "},"doc_gitbook/deploy.html":{"url":"doc_gitbook/deploy.html","title":"快速部署","keywords":"","body":" GitBook 快速部署 使用 Docker 部署 使用 Docker-Compose 部署 GitBook 快速部署使用 Docker 部署工作目录下必须存在2个文件：1. SUMMARY.md 2. README.md 假定工作目录是 ./gitbook，使用 docker 快速部署 GitBookdocker run -v ./gitbook:/srv/gitbook -p 4000:4000 fellah/gitbook:3.2.1 gitbook serve . 使用 Docker-Compose 部署docker-compose.yaml 示例：services: gitbook: restart: on-failure:10 image: fellah/gitbook:3.2.1 container_name: gitbook ports: - 4000:4000 volumes: - ./gitbook:/srv/gitbook command: gitbook serve . Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-24 "},"doc_gitbook/install_plugin.html":{"url":"doc_gitbook/install_plugin.html","title":"插件安装","keywords":"","body":" GitBook 插件安装 1.安装插件 2.编辑配置文件 3.插件生效 GitBook 插件安装1.安装插件使用 npm 安装插件，命令参数为:gitbook-plugin-插件名称 以目录折叠插件示例，如果是容器化部署可以直接在容器内执行：npm install gitbook-plugin-toggle-chapters 2.编辑配置文件项目根目录下需要有文件 bool.json，示例如下：{ \"plugins\": [ \"toggle-chapters\" ] } 3.插件生效GitBook 支持热更新，修改后会自动生效Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-24 "},"doc_gitbook/pub_to_github.html":{"url":"doc_gitbook/pub_to_github.html","title":"发布到 GitHub Pages","keywords":"","body":"GitBook 发布到 GitHub Pages新建一个项目 public 项目 books 将 GitBook 编译后的 _book 目录下的所有内容复制到 books 并推送到 GitHub 在 books 项目的 Settings -> Pages 下选择分支和 /(root) 目录后开启部署 稍等一会儿会显示 GitHub 分配的地址 Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-24 "},"doc_docker/":{"url":"doc_docker/","title":"Docker","keywords":"","body":"简介Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源。 Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。 容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低。Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-24 "},"doc_docker/docker_build.html":{"url":"doc_docker/docker_build.html","title":"Docker Build","keywords":"","body":"Docker BuildDocker Build 是 Docker Engine 最常用的功能之一。每当您创建映像时，您都在使用 Docker Build。Build 是软件开发生命周期的关键部分，可让您打包和捆绑代码并将其运送到任何地方。 Docker Build 不仅仅是一个用于构建映像的命令，也不仅仅是打包代码。它是一个完整的工具和功能生态系统，不仅支持常见的工作流任务，还为更复杂和高级的场景提供支持。Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-04-02 "},"doc_docker/core_concepts.html":{"url":"doc_docker/core_concepts.html","title":"核心概念","keywords":"","body":"核心概念Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-04-02 "},"doc_docker/docker_build_overview.html":{"url":"doc_docker/docker_build_overview.html","title":"Docker Build 概览","keywords":"","body":" Docker Build 概览 Buildx BuildKit Docker Build 概览Docker Build 实现了客户端-服务器架构，其中：客户端：Buildx 是用于运行和管理构建的客户端和用户界面。 服务端：BuildKit 是处理构建执行的服务器或构建器。 当您调用构建时，Buildx 客户端会向 BuildKit 后端发送构建请求。BuildKit 解析构建指令并执行构建步骤。构建输出要么发送回客户端，要么上传到仓库，例如 Docker Hub。 Buildx 和 BuildKit 都是随 Docker Desktop 和 Docker Engine 一起安装的，开箱即用。当您调用 docker build 命令时，您正在使用 Buildx 和 BuildKit 进行构建。BuildxBuildx 是您用来运行构建的 CLI 工具。docker build 命令是 Buildx 的包装器。当您调用 docker build 时，Buildx 会解释构建选项并向 BuildKit 后端发送构建请求。 Buildx 客户端可以做的不仅仅是构建。您还可以使用 Buildx 创建和管理 BuildKit 后端（称为构建器）。它还支持管理仓库中的映像以及同时运行多个构建的功能。 Docker Buildx 默认随 Docker Desktop 一起安装。您还可以从源代码构建 CLI 插件，或者从 GitHub 存储库中获取二进制文件并手动安装。有关更多信息，请参阅 GitHub 上的 Buildx README。虽然 docker build 在后台调用 Buildx，但此命令与规范的 docker buildx build 之间存在细微差别。有关详细信息，请参阅 docker build 和 docker buildx build 之间的区别。BuildKit一次构建从调用 docker build 命令开始。Buildx 解释您的构建命令并向 BuildKit 后端发送构建请求。构建请求包括：The Dockerfile Build arguments Export options Caching options BuildKit 解析构建指令并执行构建步骤。在 BuildKit 执行构建时，Buildx 会监控构建状态并将进度打印到终端。 如果构建需要来自客户端的资源（例如本地文件或构建机密），BuildKit 会从 Buildx 请求所需的资源。与早期版本的 Docker 中使用的旧构建器相比，这是 BuildKit 更高效的一种方式。BuildKit 仅在需要时请求构建所需的资源。相比之下，旧构建器始终获取本地文件系统的副本。 BuildKit 可以从 Buildx 请求的资源示例包括：Local filesystem build contexts Build secrets SSH sockets Registry authentication tokens Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-04-02 "},"doc_docker/dockerfile_overview.html":{"url":"doc_docker/dockerfile_overview.html","title":"Dockerfile 概览","keywords":"","body":" Dockerfile 概览 Dockerfile Filename Docker images Example Dockerfile syntax Base image Environment setup Comments Installing dependencies Copying files Setting environment variables Exposed ports Starting the application Building Dockerfile 概览Dockerfile一切都从 Dockerfile 开始。Docker 通过读取 Dockerfile 中的指令来构建镜像。Dockerfile 是一个文本文件，其中包含构建源代码的指令。Dockerfile 指令语法由 Dockerfile Reference 中的规范定义。以下是最常见的指令类型： 指令 描述 `FROM ` 为你的镜像定义一个基础镜像 `RUN ` 在当前镜像之上的新层执行命令并提交结构，`RUN` 还具有运行命令的 Shell 形式 `WORKDIR ` 给该指令后的任意指令如 `RUN`、`CMD`、`ENTRYPOINT`、`COPY`、`ADD` 等设置工作目录 `COPY ` 拷贝 `` 文件或目录到容器的文件系统路径 `` `CMD ` 指定容器的默认运行程序，存在多个时只有最后一个生效 Dockerfile 是镜像构建的关键输入，可以根据您的独特配置促进自动化、多层镜像构建。Dockerfile 可以从简单开始，并根据您的需求扩展以支持更复杂的场景。FilenameDockerfile 的默认文件名就是 Dockerfile，不加后缀可以让 docker build 指令直接识别。 如果构建复杂，一般使用 .Dockerfile 的方式命名，并用 --file 标记来指定文件。建议给工程最主要的 Dockerfile 命名成 Dockerfile。Docker imagesDocker 镜像由层组成。每一层都是 Dockerfile 中构建指令的结果。层按顺序堆叠，每一层都是一个增量，表示应用于上一层的更改。Example# syntax=docker/dockerfile:1 FROM ubuntu:22.04 # install app dependencies RUN apt-get update && apt-get install -y python3 python3-pip RUN pip install flask==3.0.* # install app COPY hello.py / # final configuration ENV FLASK_APP=hello EXPOSE 8000 CMD [\"flask\", \"run\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"] Dockerfile syntax指定 dockfile 解析版本# syntax=docker/dockerfile:1 第一行指定了使用主版本是1的dockerfile解析器，它实际是一个存储在 Docker Hub 上的轻量级镜像（类似插件），包含了解析 Dockerfile 的工具链。构建时，Docker 会动态加载它。可以查看官方镜像标签页确定最新版本。如果不写这一行，Docker 会默认使用当前安装的 Docker 引擎内置的 Dockerfile 解析器来构建镜像Base image声明了 ubuntu 的 22.04 版本的镜像FROM ubuntu:22.04 Environment setup安装依赖# install app dependencies RUN apt-get update && apt-get install -y python3 python3-pip Comments注释行# install app dependencies 回顾 # syntax=docker/dockerfile:1，注意只有出现在文件开头，并且使用了 syntax directive 的行不会被当作注释Installing dependencies安装依赖RUN pip install flask==3.0.* Copying files拷贝文件到容器COPY hello.py / Setting environment variables设置环境变量ENV FLASK_APP=hello Exposed ports暴露端口EXPOSE 8000 这只是一个声明，并非强制要求。即使不写，也不影响容器暴露端口。但是这是一个良好的规范，比如写了之后方便其他人通过 docker inspect 查看该容器可能暴露的端口Starting the application运行应用，推荐使用第一种，第一种直接运行 flask，第二种使用 shell 运行 flask，导致主进程不是 flask，会影响 SIGTERM 等信号传递CMD [\"flask\", \"run\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"] CMD flask run --host 0.0.0.0 --port 8000 Buildingdocker build -t test:latest . (.)用来指定 build context，即 Dockerfile 和构建所需文件路径。构建完成后使用下列命令启动容器：docker run -p 127.0.0.1:8000:8000 test:latest 在 VSCode 安装扩展 Docker VS Code Extension (Beta) 来更好的编写 DockerfileCopyright ©ZhangFeng all right reserved，powered by Gitbook 2025-04-02 "},"doc_docker/cache.html":{"url":"doc_docker/cache.html","title":"加速 Golang 程序构建","keywords":"","body":"Docker 加速 Golang 程序构建挂载Go编译缓存：通过--mount=type=cache,target=/root/.cache/go-build，将宿主机的缓存目录挂载到容器内部的/root/.cache/go-build路径下。这可以加快Go代码的编译速度，因为Go编译器会在这里存放已经编译过的包的缓存。 挂载Go的pkg缓存：通过--mount=type=cache,target=/go/pkg，这个挂载点主要是用来存储已经下载的依赖包，从而在后续构建过程中如果需要相同的依赖版本，则不需要再次从网络下载。 # 缓存依赖 & 打包 RUN --mount=type=cache,target=/root/.cache/go-build \\ --mount=type=cache,target=/go/pkg \\ go build . Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-24 "},"doc_docker/multi_arch.html":{"url":"doc_docker/multi_arch.html","title":"支持运行不同架构容器","keywords":"","body":" Docker 支持运行不同架构容器 安装 qemu 注册 qemu 检查安装 Docker 支持运行不同架构容器安装 qemusudo apt-get update sudo apt-get install -y qemu-user-static binfmt-support qemu-user-static 是一个用于在 Linux 系统上运行非本机架构（cross-architecture）二进制文件的工具。它是 QEMU（Quick Emulator）的一部分，专注于用户态模拟（user-mode emulation），允许你在一个架构的系统上运行另一种架构的二进制文件，而无需完整的虚拟机或系统级模拟。binfmt-support 是一个用于管理 Linux 内核 binfmt_misc 模块的工具，主要用于支持运行非本机架构的二进制文件。它在跨架构容器运行（如 Docker）和开发测试中非常有用。通过结合 QEMU 模拟器，它可以实现无缝的多架构支持。注册 qemudocker run --rm --privileged multiarch/qemu-user-static --reset -p yes 检查安装docker buildx inspect --bootstrap | grep Platforms 可以看到支持了以下架构:Platforms: linux/amd64, linux/amd64/v2, linux/amd64/v3, linux/amd64/v4, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/mips64le, linux/mips64, linux/arm/v7, linux/arm/v6 或者可以在 docker builds 界面看到支持的架构 Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-24 "},"doc_web/":{"url":"doc_web/","title":"Web","keywords":"","body":"Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-06-17 "},"doc_web/cat.html":{"url":"doc_web/cat.html","title":"猫猫网页","keywords":"","body":" 猫猫网页 index.html 猫猫网页index.html CatPhotoApp CatPhotoApp Cat Photos Everyone loves cute cats online! See more cat photos in our gallery. Cat Lists Things cats love: catnip laser pointers lasagna Cats love lasagna. Top 3 things cats hate: flea treatment thunder other cats Cats hate other cats. Cat Form Is your cat an indoor or outdoor cat? Indoor Outdoor What's your cat's personality? Loving Lazy Energetic Submit No Copyright - freeCodeCamp.org Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-25 "},"doc_web/cafe.html":{"url":"doc_web/cafe.html","title":"咖啡菜单","keywords":"","body":" 咖啡菜单 index.html styles.css 咖啡菜单index.html Cafe Menu CAMPER CAFE Est. 2020 Coffee French Vanilla 3.00 Caramel Macchiato 3.75 Pumpkin Spice 3.50 Hazelnut 4.00 Mocha 4.50 Desserts Donut 1.50 Cherry Pie 2.75 Cheesecake 3.00 Cinnamon Roll 2.50 Visit our website 123 Free Code Camp Drive styles.cssbody { background-image: url(https://cdn.freecodecamp.org/curriculum/css-cafe/beans.jpg); font-family: sans-serif; padding: 20px; } h1 { font-size: 40px; margin-top: 0; margin-bottom: 15px; } h2 { font-size: 30px; } .established { font-style: italic; } h1, h2, p { text-align: center; } .menu { width: 80%; background-color: burlywood; margin-left: auto; margin-right: auto; padding: 20px; max-width: 500px; } img { display: block; margin-left: auto; margin-right: auto; margin-top: -25px; } hr { height: 2px; background-color: brown; border-color: brown; } .bottom-line { margin-top: 25px; } h1, h2 { font-family: Impact, serif; } .item p { display: inline-block; margin-top: 5px; margin-bottom: 5px; font-size: 18px; } .flavor, .dessert { text-align: left; width: 75%; } .price { text-align: right; width: 24%; } /* FOOTER */ footer { font-size: 14px; } .address { margin-bottom: 5px; } a { color: black; } a:visited { color: black; } a:hover { color: brown; } a:active { color: brown; } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-25 "},"doc_web/markers.html":{"url":"doc_web/markers.html","title":"颜料笔","keywords":"","body":" 颜料笔 index.html styles.css 颜料笔index.html Colored Markers CSS Color Markers styles.cssh1 { text-align: center; } .container { background-color: rgb(255, 255, 255); padding: 10px 0; } .marker { width: 200px; height: 25px; margin: 10px auto; } .cap { width: 60px; height: 25px; } .sleeve { width: 110px; height: 25px; background-color: rgba(255, 255, 255, 0.5); border-left: 10px double rgba(0, 0, 0, 0.75); } .cap, .sleeve { display: inline-block; } .red { background: linear-gradient(rgb(122, 74, 14), rgb(245, 62, 113), rgb(162, 27, 27)); box-shadow: 0 0 20px 0 rgba(83, 14, 14, 0.8); } .green { background: linear-gradient(#55680D, #71F53E, #116C31); box-shadow: 0 0 20px 0 #3B7E20CC; } .blue { background: linear-gradient(hsl(186, 76%, 16%), hsl(223, 90%, 60%), hsl(240, 56%, 42%)); box-shadow: 0 0 20px 0 hsla(223, 59%, 31%, 0.8); } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-25 "},"doc_web/registration.html":{"url":"doc_web/registration.html","title":"注册页面","keywords":"","body":" 注册页面 index.html styles.css 注册页面index.html Registration Form Registration Form Please fill out this form with the required information Enter Your First Name: Enter Your Last Name: Enter Your Email: Create a New Password: Account type (required) Personal Business Upload a profile picture: Input your age (years): How did you hear about us? (select one) freeCodeCamp News freeCodeCamp YouTube Channel freeCodeCamp Forum Other Provide a bio: I accept the terms and conditions styles.cssbody { width: 100%; height: 100vh; margin: 0; background-color: #1b1b32; color: #f5f6f7; font-family: Tahoma; font-size: 16px; } h1, p { margin: 1em auto; text-align: center; } form { width: 60vw; max-width: 500px; min-width: 300px; margin: 0 auto; padding-bottom: 2em; } fieldset { border: none; padding: 2rem 0; border-bottom: 3px solid #3b3b4f; } fieldset:last-of-type { border-bottom: none; } label { display: block; margin: 0.5rem 0; } input, textarea, select { margin: 10px 0 0 0; width: 100%; min-height: 2em; } input, textarea { background-color: #0a0a23; border: 1px solid #0a0a23; color: #ffffff; } .inline { width: unset; margin: 0 0.5em 0 0; vertical-align: middle; } input[type=\"submit\"] { display: block; width: 60%; margin: 1em auto; height: 2em; font-size: 1.1rem; background-color: #3b3b4f; border-color: white; min-width: 300px; } input[type=\"file\"] { padding: 1px 2px; } a { color: #dfdfe2; } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-25 "},"doc_web/box.html":{"url":"doc_web/box.html","title":"盒模型","keywords":"","body":" 盒模型 index.html styles.css 盒模型 index.html Rothko Painting styles.css.canvas { width: 500px; height: 600px; background-color: #4d0f00; overflow: hidden; filter: blur(2px); } .frame { border: 50px solid black; width: 500px; padding: 50px; margin: 20px auto; } .one { width: 425px; height: 150px; background-color: #efb762; margin: 20px auto; box-shadow: 0 0 3px 3px #efb762; border-radius: 9px; transform: rotate(-0.6deg); } .two { width: 475px; height: 200px; background-color: #8f0401; margin: 0 auto 20px; box-shadow: 0 0 3px 3px #8f0401; border-radius: 8px 10px; transform: rotate(0.4deg); } .one, .two { filter: blur(1px); } .three { width: 91%; height: 28%; background-color: #b20403; margin: auto; filter: blur(2px); box-shadow: 0 0 5px 5px #b20403; border-radius: 30px 25px 60px 12px; transform: rotate(-0.2deg); } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-26 "},"doc_web/flexbox.html":{"url":"doc_web/flexbox.html","title":"弹性盒模型","keywords":"","body":" 弹性盒模型 index.html styles.css 弹性盒模型index.html Photo Gallery css flexbox photo gallery styles.css* { box-sizing: border-box; } body { margin: 0; font-family: sans-serif; background: #f5f6f7; } .header { text-align: center; text-transform: uppercase; padding: 32px; background-color: #0a0a23; color: #fff; border-bottom: 4px solid #fdb347; } .gallery { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: center; align-items: center; gap: 16px; max-width: 1400px; margin: 0 auto; padding: 20px 10px; } .gallery img { width: 100%; max-width: 350px; height: 300px; object-fit: cover; border-radius: 10px; } .gallery::after { content: \"\"; width: 350px; } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-25 "},"doc_web/nutrition.html":{"url":"doc_web/nutrition.html","title":"营养表","keywords":"","body":" 营养表 index.html styles.css 营养表index.html Nutrition Label Nutrition Facts 8 servings per container Serving size 2/3 cup (55g) Amount per serving Calories 230 % Daily Value * Total Fat 8g 10% Saturated Fat 1g 5% Trans Fat 0g Cholesterol 0mg 0% Sodium 160mg 7% Total Carbohydrate 37g 13% Dietary Fiber 4g Total Sugars 12g Includes 10g Added Sugars 20% Protein 3g Vitamin D 2mcg 10% Calcium 260mg 20% Iron 8mg 45% Potassium 235mg 6% * The % Daily Value (DV) tells you how much a nutrient in a serving of food contributes to a daily diet. 2,000 calories a day is used for general nutrition advice. styles.css* { box-sizing: border-box; } html { font-size: 16px; } body { font-family: 'Open Sans', sans-serif; } .label { border: 2px solid black; width: 270px; margin: 20px auto; padding: 0 7px; } header h1 { text-align: center; margin: -4px 0; letter-spacing: 0.15px } p { margin: 0; display: flex; justify-content: space-between; } .divider { border-bottom: 1px solid #888989; margin: 2px 0; } .bold { font-weight: 800; } .large { height: 10px; } .large, .medium { background-color: black; border: 0; } .medium { height: 5px; } .small-text { font-size: 0.85rem; } .calories-info { display: flex; justify-content: space-between; align-items: flex-end; } .calories-info h2 { margin: 0; } .left-container p { margin: -5px -2px; font-size: 2em; font-weight: 700; } .calories-info span { margin: -7px -2px; font-size: 2.4em; font-weight: 700; } .right { justify-content: flex-end; } .indent { margin-left: 1em; } .double-indent { margin-left: 2em; } .daily-value p:not(.no-divider) { border-bottom: 1px solid #888989; } .note { font-size: 0.6rem; margin: 5px 0; padding: 0 8px; text-indent: -8px; } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-25 "},"doc_web/accessibility.html":{"url":"doc_web/accessibility.html","title":"无障碍阅读","keywords":"","body":" 无障碍阅读 index.html styles.css 无障碍阅读index.html Accessibility Quiz HTML/CSS Quiz INFO HTML CSS Student Info Name: Email: Date of Birth: HTML Question1 The legend element represents a caption for the content of its parent fieldset element True False Question2 A label element nesting an input element is required to have a for attribute with the same value as the input's id True False CSS Can the CSS margin property accept negative values? Select an option Yes No Do you have any questions: Send freeCodeCamp San Francisco California USA styles.css/* 平滑滚动设置：仅在用户未开启\"减少动画\"偏好时启用 */ @media (prefers-reduced-motion: no-preference) { * { scroll-behavior: smooth; /* 启用平滑滚动效果 */ } } /* 全局基础样式 */ body { background: #f5f6f7; /* 页面背景色 */ color: #1b1b32; /* 默认文字颜色 */ font-family: Helvetica; /* 默认字体 */ margin: 0; /* 移除默认外边距 */ } /* 页眉样式 */ header { width: 100%; /* 全宽 */ height: 50px; /* 固定高度 */ background-color: #1b1b32; /* 深色背景 */ display: flex; /* 弹性布局 */ justify-content: space-between; /* 两端对齐 */ align-items: center; /* 垂直居中 */ top: 0; /* 顶部对齐 */ } /* Logo样式 */ #logo { width: max(10rem, 18vw); /* 响应式宽度 */ background-color: #0a0a23; /* Logo背景色 */ aspect-ratio: 35 / 4; /* 固定宽高比 */ padding: 0.4rem; /* 内边距 */ } /* 主标题样式 */ h1 { color: #f1be32; /* 金色文字 */ font-size: min(5vw, 1.2em); /* 响应式字体大小 */ text-align: center; /* 居中显示 */ } /* 导航栏容器 */ nav { width: 50%; /* 占据50%宽度 */ max-width: 300px; /* 最大宽度限制 */ height: 50px; /* 与header同高 */ } /* 导航菜单列表 */ nav>ul { display: flex; /* 弹性布局 */ justify-content: space-evenly; /* 均匀分布 */ flex-wrap: wrap; /* 允许换行 */ align-items: center; /* 垂直居中 */ padding-inline-start: 0; /* 移除默认左内边距 */ margin-block: 0; /* 移除默认外边距 */ height: 100%; /* 继承父元素高度 */ } /* 导航菜单项 */ nav>ul>li { color: #dfdfe2; /* 浅色文字 */ margin: 0 0.2rem; /* 左右外边距 */ padding: 0.2rem; /* 内边距 */ display: block; /* 块级显示 */ } /* 导航菜单悬停效果 */ nav>ul>li:hover { background-color: #dfdfe2; /* 背景色变化 */ color: #1b1b32; /* 文字颜色变化 */ cursor: pointer; /* 鼠标指针变化 */ } /* 导航链接样式 */ li>a { color: inherit; /* 继承父元素颜色 */ text-decoration: none; /* 移除下划线 */ } /* 主内容区域 */ main { padding-top: 50px; /* 顶部内边距，防止被header遮挡 */ } /* 内容区块样式 */ section { width: 80%; /* 宽度占比 */ margin: 0 auto 10px auto; /* 水平居中，底部外边距 */ max-width: 600px; /* 最大宽度限制 */ } /* 标题字体设置 */ h1, h2 { font-family: Verdana, Tahoma; /* 指定字体 */ } /* 二级标题样式 */ h2 { border-bottom: 4px solid #dfdfe2; /* 底部边框 */ margin-top: 0px; /* 移除顶部外边距 */ padding-top: 60px; /* 顶部内边距 */ } /* 信息区域样式 */ .info { padding: 10px 0 0 5px; /* 自定义内边距 */ } /* 表单行样式 */ .formrow { margin-top: 30px; /* 顶部外边距 */ padding: 0px 15px; /* 左右内边距 */ } /* 输入框基础样式 */ input { font-size: 1rem; /* 标准字体大小 */ } /* 信息标签和输入框布局 */ .info label, .info input { display: inline-block; /* 行内块布局 */ } /* 信息输入框样式 */ .info input { width: 50%; /* 宽度占比 */ text-align: left; /* 文字左对齐 */ } /* 信息标签样式 */ .info label { width: 10%; /* 宽度占比 */ min-width: 55px; /* 最小宽度 */ text-align: right; /* 文字右对齐 */ } /* 问题区块样式 */ .question-block { text-align: left; /* 文字左对齐 */ display: block; /* 块级显示 */ width: 100%; /* 全宽 */ margin-top: 20px; /* 顶部外边距 */ padding-top: 5px; /* 顶部内边距 */ } /* 三级标题样式 */ h3 { margin-top: 5px; /* 顶部外边距 */ padding-left: 15px; /* 左内边距 */ font-size: 1.375rem; /* 字体大小 */ } /* 三级标题前缀 */ h3::before { content: \"Question #\"; /* 添加前缀内容 */ } /* 问题样式 */ .question { border: none; /* 无边框 */ padding-bottom: 0; /* 底部无内边距 */ } /* 答案列表样式 */ .answers-list { list-style: none; /* 移除列表标记 */ padding: 0; /* 移除内边距 */ } /* 按钮样式 */ button { display: block; /* 块级显示 */ margin: 40px auto; /* 外边距自动居中 */ width: 40%; /* 宽度占比 */ padding: 15px; /* 内边距 */ font-size: 1.438rem; /* 字体大小 */ background: #d0d0d5; /* 背景色 */ border: 3px solid #3b3b4f; /* 边框样式 */ } /* 页脚样式 */ footer { background-color: #2a2a40; /* 深色背景 */ display: flex; /* 弹性布局 */ justify-content: center; /* 内容居中 */ } /* 页脚文字和链接样式 */ footer, footer a { color: #dfdfe2; /* 浅色文字 */ } /* 地址样式 */ address { text-align: center; /* 文字居中 */ padding: 0.3em; /* 内边距 */ } /* 屏幕阅读器专用样式（隐藏元素但可被阅读器读取） */ .sr-only { position: absolute; /* 绝对定位 */ width: 1px; /* 极小宽度 */ height: 1px; /* 极小高度 */ overflow: hidden; /* 隐藏溢出 */ clip: rect(0, 0, 0, 0); /* 裁剪元素 */ clip-path: inset(50%); /* 进一步裁剪 */ white-space: nowrap; /* 防止换行 */ } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-26 "},"doc_web/balance.html":{"url":"doc_web/balance.html","title":"资产表","keywords":"","body":" 资产表 index.html styles.css 资产表index.html Balance Sheet AcmeWidgetCorp Balance Sheet 2019 2020 2021 Assets 2019 2020 2021 Cash This is the cash we currently have on hand. $25 $30 $28 Checking Our primary transactional account. $54 $56 $53 Savings Funds set aside for emergencies. $500 $650 $728 Total Assets $579 $736 $809 Liabilities 2019 2020 2021 Loans The outstanding balance on our startup loan. $500 $250 $0 Expenses Annual anticipated expenses, such as payroll. $200 $300 $400 Credit The outstanding balance on our credit card. $50 $50 $75 Total Liabilities $750 $600 $475 Net Worth 2019 2020 2021 Total Net Worth $-171 $136 $334 styles.cssspan[class~=\"sr-only\"] { border: 0 !important; clip: rect(1px, 1px, 1px, 1px) !important; clip-path: inset(50%) !important; height: 1px !important; width: 1px !important; position: absolute !important; overflow: hidden !important; white-space: nowrap !important; padding: 0 !important; margin: -1px !important; } html { box-sizing: border-box; } body { font-family: sans-serif; color: #0a0a23; } h1 { max-width: 37.25rem; margin: 0 auto; padding: 1.5rem 1.25rem; } h1 .flex { display: flex; flex-direction: column-reverse; gap: 1rem; } h1 .flex span:first-of-type { font-size: 0.7em; } h1 .flex span:last-of-type { font-size: 1.2em; } section { max-width: 40rem; margin: 0 auto; border: 2px solid #d0d0d5; } #years { display: flex; justify-content: flex-end; position: sticky; z-index: 999; top: 0; background: #0a0a23; color: #fff; padding: 0.5rem calc(1.25rem + 2px) 0.5rem 0; margin: 0 -2px; } #years span[class] { font-weight: bold; width: 4.5rem; text-align: right; } .table-wrap { padding: 0 0.75rem 1.5rem 0.75rem; } table { border-collapse: collapse; border: 0; width: 100%; position: relative; margin-top: 3rem; } table caption { color: #356eaf; font-size: 1.3em; font-weight: normal; position: absolute; top: -2.25rem; left: 0.5rem; } tbody td { width: 100vw; min-width: 4rem; max-width: 4rem; } tbody th { width: calc(100% - 12rem); } tr[class=\"total\"] { border-bottom: 4px double #0a0a23; font-weight: bold; } tr[class=\"total\"] th { text-align: left; padding: 0.5rem 0 0.25rem 0.5rem; } tr.total td { text-align: right; padding: 0 0.25rem; } tr.total td:nth-of-type(3) { padding-right: 0.5rem; } tr.total:hover { background-color: #99c9ff; } td.current { font-style: italic; } tr.data { background-image: linear-gradient(to bottom, #dfdfe2 1.845rem, white 1.845rem); } tr.data th { text-align: left; padding-top: 0.3rem; padding-left: 0.5rem; } tr.data th .description { display: block; font-weight: normal; font-style: italic; padding: 1rem 0 0.75rem; margin-right: -13.5rem; } tr.data td { vertical-align: top; padding: 0.3rem 0.25rem 0; text-align: right; } tr.data td:last-of-type { padding-right: 0.5rem; } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-27 "},"doc_web/draw_cat.html":{"url":"doc_web/draw_cat.html","title":"画猫猫","keywords":"","body":" 画猫猫 index.html styles.css 画猫猫index.html fCC Cat Painting styles.css* { box-sizing: border-box; } body { background-color: #c9d2fc; } .cat-head { position: absolute; right: 0; left: 0; top: 0; bottom: 0; margin: auto; background: linear-gradient(#5e5e5e 85%, #45454f 100%); width: 205px; height: 180px; border: 1px solid #000; border-radius: 46%; } .cat-left-ear { position: absolute; top: -26px; left: -31px; z-index: 1; border-top-left-radius: 90px; border-top-right-radius: 10px; transform: rotate(-45deg); border-left: 35px solid transparent; border-right: 35px solid transparent; border-bottom: 70px solid #5e5e5e; } .cat-right-ear { position: absolute; top: -26px; left: 163px; z-index: 1; transform: rotate(45deg); border-top-left-radius: 90px; border-top-right-radius: 10px; border-left: 35px solid transparent; border-right: 35px solid transparent; border-bottom: 70px solid #5e5e5e; } .cat-left-inner-ear { position: absolute; top: 22px; left: -20px; border-top-left-radius: 90px; border-top-right-radius: 10px; border-bottom-right-radius: 40%; border-bottom-left-radius: 40%; border-left: 20px solid transparent; border-right: 20px solid transparent; border-bottom: 40px solid #3b3b4f; } .cat-right-inner-ear { position: absolute; top: 22px; left: -20px; border-top-left-radius: 90px; border-top-right-radius: 10px; border-bottom-right-radius: 40%; border-bottom-left-radius: 40%; border-left: 20px solid transparent; border-right: 20px solid transparent; border-bottom: 40px solid #3b3b4f; } .cat-left-eye { position: absolute; top: 54px; left: 39px; border-radius: 60%; transform: rotate(25deg); width: 30px; height: 40px; background-color: #000; } .cat-right-eye { position: absolute; top: 54px; left: 134px; border-radius: 60%; transform: rotate(-25deg); width: 30px; height: 40px; background-color: #000; } .cat-left-inner-eye { position: absolute; top: 8px; left: 2px; width: 10px; height: 20px; transform: rotate(10deg); background-color: #fff; border-radius: 60%; } .cat-right-inner-eye { position: absolute; top: 8px; left: 18px; transform: rotate(-5deg); width: 10px; height: 20px; background-color: #fff; border-radius: 60%; } .cat-nose { position: absolute; top: 108px; left: 85px; border-top-left-radius: 50%; border-bottom-right-radius: 50%; border-bottom-left-radius: 50%; transform: rotate(180deg); border-left: 15px solid transparent; border-right: 15px solid transparent; border-bottom: 20px solid #442c2c; } .cat-mouth div { width: 30px; height: 50px; border: 2px solid #000; border-radius: 190%/190px 150px 0 0; border-color: black transparent transparent transparent; } .cat-mouth-line-left { position: absolute; top: 88px; left: 74px; transform: rotate(170deg); } .cat-mouth-line-right { position: absolute; top: 88px; left: 91px; transform: rotate(165deg); } .cat-whiskers-left div { width: 40px; height: 1px; background-color: #000; } .cat-whiskers-right div { width: 40px; height: 1px; background-color: #000; } .cat-whisker-left-top { position: absolute; top: 120px; left: 52px; transform: rotate(10deg); } .cat-whisker-left-middle { position: absolute; top: 127px; left: 52px; transform: rotate(3deg); } .cat-whisker-left-bottom { position: absolute; top: 134px; left: 52px; transform: rotate(-3deg); } .cat-whisker-right-top { position: absolute; top: 120px; left: 109px; transform: rotate(-10deg); } .cat-whisker-right-middle { position: absolute; top: 127px; left: 109px; transform: rotate(-3deg); } .cat-whisker-right-bottom { position: absolute; top: 134px; left: 109px; transform: rotate(3deg); } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-04-02 "},"doc_web/piano.html":{"url":"doc_web/piano.html","title":"画钢琴","keywords":"","body":" 钢琴 index.html styles.css 钢琴index.html Piano styles.csshtml { box-sizing: border-box; } *, *::before, *::after { box-sizing: inherit; } #piano { background-color: #00471b; width: 992px; height: 290px; margin: 80px auto; padding: 90px 20px 0 20px; position: relative; border-radius: 10px; } .keys { background-color: #040404; width: 949px; height: 180px; padding-left: 2px; overflow: hidden; } .key { background-color: #ffffff; position: relative; width: 41px; height: 175px; margin: 2px; float: left; border-radius: 0 0 3px 3px; } .key.black--key::after { background-color: #1d1e22; content: \"\"; position: absolute; left: -18px; width: 32px; height: 100px; border-radius: 0 0 3px 3px; } .logo { width: 200px; position: absolute; top: 23px; } @media (max-width: 768px) { #piano { width: 358px; } .keys { width: 318px; } .logo { width: 150px; } } @media (max-width: 1199px) and (min-width: 769px) { #piano { width: 675px; } .keys { width: 633px; } .logo { width: 633px; } } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-04-02 "},"doc_web/city.html":{"url":"doc_web/city.html","title":"城市天际线","keywords":"","body":" 城市天际线 index.html styles.css 城市天际线 index.html City Skyline styles.css:root { --building-color1: #aa80ff; --building-color2: #66cc99; --building-color3: #cc6699; --building-color4: #538cc6; --window-color1: #bb99ff; --window-color2: #8cd9b3; --window-color3: #d98cb3; --window-color4: #8cb3d9; } * { box-sizing: border-box; } body { height: 100vh; margin: 0; overflow: hidden; } .background-buildings, .foreground-buildings { width: 100%; height: 100%; display: flex; align-items: flex-end; justify-content: space-evenly; position: absolute; top: 0; } .building-wrap { display: flex; flex-direction: column; align-items: center; } .window-wrap { display: flex; align-items: center; justify-content: space-evenly; } .sky { background: radial-gradient( closest-corner circle at 15% 15%, #ffcf33, #ffcf33 20%, #ffff66 21%, #bbeeff 100% ); } /* BACKGROUND BUILDINGS - \"bb\" stands for \"background building\" */ .bb1 { width: 10%; height: 70%; } .bb1a { width: 70%; } .bb1b { width: 80%; } .bb1c { width: 90%; } .bb1d { width: 100%; height: 70%; background: linear-gradient( var(--building-color1) 50%, var(--window-color1) ); } .bb1-window { height: 10%; background: linear-gradient( var(--building-color1), var(--window-color1) ); } .bb2 { width: 10%; height: 50%; } .bb2a { border-bottom: 5vh solid var(--building-color2); border-left: 5vw solid transparent; border-right: 5vw solid transparent; } .bb2b { width: 100%; height: 100%; background: repeating-linear-gradient( var(--building-color2), var(--building-color2) 6%, var(--window-color2) 6%, var(--window-color2) 9% ); } .bb3 { width: 10%; height: 55%; background: repeating-linear-gradient( 90deg, var(--building-color3), var(--building-color3), var(--window-color3) 15% ); } .bb4 { width: 11%; height: 58%; } .bb4a { width: 3%; height: 10%; background-color: var(--building-color4); } .bb4b { width: 80%; height: 5%; background-color: var(--building-color4); } .bb4c { width: 100%; height: 85%; background-color: var(--building-color4); } .bb4-window { width: 18%; height: 90%; background-color: var(--window-color4); } /* FOREGROUND BUILDINGS - \"fb\" stands for \"foreground building\" */ .fb1 { width: 10%; height: 60%; } .fb1a { border-bottom: 7vh solid var(--building-color4); border-left: 2vw solid transparent; border-right: 2vw solid transparent; } .fb1b { width: 60%; height: 10%; background-color: var(--building-color4); } .fb1c { width: 100%; height: 80%; background: repeating-linear-gradient( 90deg, var(--building-color4), var(--building-color4) 10%, transparent 10%, transparent 15% ), repeating-linear-gradient( var(--building-color4), var(--building-color4) 10%, var(--window-color4) 10%, var(--window-color4) 90% ); } .fb2 { width: 10%; height: 40%; } .fb2a { width: 100%; border-bottom: 10vh solid var(--building-color3); border-left: 1vw solid transparent; border-right: 1vw solid transparent; } .fb2b { width: 100%; height: 75%; background-color: var(--building-color3); } .fb2-window { width: 22%; height: 100%; background-color: var(--window-color3); } .fb3 { width: 10%; height: 35%; } .fb3a { width: 80%; height: 15%; background-color: var(--building-color1); } .fb3b { width: 100%; height: 35%; background-color: var(--building-color1); } .fb3-window { width: 25%; height: 80%; background-color: var(--window-color1); } .fb4 { width: 8%; height: 45%; position: relative; left: 10%; } .fb4a { border-top: 5vh solid transparent; border-left: 8vw solid var(--building-color1); } .fb4b { width: 100%; height: 89%; background-color: var(--building-color1); display: flex; flex-wrap: wrap; } .fb4-window { width: 30%; height: 10%; border-radius: 50%; background-color: var(--window-color1); margin: 10%; } .fb5 { width: 10%; height: 33%; position: relative; right: 10%; background: repeating-linear-gradient( var(--building-color2), var(--building-color2) 5%, transparent 5%, transparent 10% ), repeating-linear-gradient( 90deg, var(--building-color2), var(--building-color2) 12%, var(--window-color2) 12%, var(--window-color2) 44% ); } .fb6 { width: 9%; height: 38%; background: repeating-linear-gradient( 90deg, var(--building-color3), var(--building-color3) 10%, transparent 10%, transparent 30% ), repeating-linear-gradient( var(--building-color3), var(--building-color3) 10%, var(--window-color3) 10%, var(--window-color3) 30% ); } @media (max-width: 1000px) { :root { --building-color1: #000; --building-color2: #000; --building-color3: #000; --building-color4: #000; } .sky { background: radial-gradient( closest-corner circle at 15% 15%, #ccc, #ccc 20%, #445 21%, #223 100% ); } } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-04-02 "},"doc_web/magazine.html":{"url":"doc_web/magazine.html","title":"杂志","keywords":"","body":" 杂志 index.html styles.css 杂志index.html Magazine OUR NEW CURRICULUM Our efforts to restructure our curriculum with a more project-based focus By freeCodeCamp March 7, 2019 Soon the freeCodeCamp curriculum will be 100% project-driven learning. Instead of a series of coding challenges, you'll learn through building projects - step by step. Before we get into the details, let me emphasize: we are not changing the certifications. All 6 certifications will still have the same 5 required projects. We are only changing the optional coding challenges. After years - years - of pondering these two problems and how to solve them, I slipped, hit my head on the sink, and when I came to I had a revelation! A vision! A picture in my head! A picture of this! This is what makes time travel possible: the flux capacitor! It wasn't as dramatic as Doc's revelation in Back to the Future. It just occurred to me while I was going for a run. The revelation: the entire curriculum should be a series of projects. Instead of individual coding challenges, we'll just have projects, each with their own seamless series of tests. Each test gives you just enough information to figure out how to get it to pass. (And you can view hints if that isn't enough.) The entire curriculum should be a series of projects No more walls of explanatory text. No more walls of tests. Just one test at a time, as you build up a working project. Over the course of passing thousands of tests, you build up projects and your own understanding of coding fundamentals. There is no transition between lessons and projects, because the lessons themselves are baked into projects. And there's plenty of repetition to help you retain everything because - hey - building projects in real life has plenty of repetition. The main design challenge is taking what is currently paragraphs of explanation and instructions and packing them into a single test description text. Each project will involve dozens of tests like this. People will be coding the entire time, rather than switching back and forth from \"reading mode\" to \"coding mode\". Instead of a series of coding challenges, people will be in their code editor passing one test after another, quickly building up a project. People will get into a real flow state, similar to what they experience when they build the required projects at the end of each certification. They'll get that sense of forward progress right from the beginning. And freeCodeCamp will be a much smoother experience. A Brief History Of the Curriculum V1 - 2014 We launched freeCodeCamp with a simple list of 15 resources, including Harvard's CS50 and Stanford's Database Class. V2 - 2015 We added interactive algorithm challenges. V3 - 2015 We added our own HTML+CSS challenges (before we'd been relying on General Assembly's Dash course for these). V4 - 2016 We expanded the curriculum to 3 certifications, including Front End, Back End, and Data Visualization. They each had 10 required projects, but only the Front End section had its own challenges. For the other certs, we were still using external resources like Node School. V5 - 2017 We added the back end and data visualization challenges. V6 - 2018 We launched 6 new certifications to replace our old ones. This was the biggest curriculum improvement to date. The millions of people who are learning to code through freeCodeCamp will have an even better resource to help them learn these fundamentals. styles.css*, ::before, ::after { padding: 0; margin: 0; box-sizing: border-box; } html { font-size: 62.5%; } body { font-family: 'Baskervville', serif; color: linen; background-color: rgb(20, 30, 40); } h1 { font-family: 'Anton', sans-serif; } h2, h3, h4, h5, h6 { font-family: 'Raleway', sans-serif; } a { text-decoration: none; color: linen; } main { display: grid; grid-template-columns: minmax(2rem, 1fr) minmax(min-content, 94rem) minmax(2rem, 1fr); row-gap: 3rem; } img { width: 100%; object-fit: cover; } hr { margin: 1.5rem 0; border: 1px solid rgba(120, 120, 120, 0.6); } .heading { grid-column: 2 / 3; display: grid; grid-template-columns: repeat(2, 1fr); row-gap: 1.5rem; } .text { grid-column: 2 / 3; font-size: 1.8rem; letter-spacing: 0.6px; column-width: 25rem; text-align: justify; } .hero { grid-column: 1 / -1; position: relative; } .hero-title { text-align: center; color: orangered; font-size: 8rem; } .hero-subtitle { font-size: 2.4rem; color: orangered; text-align: center; } .author { font-size: 2rem; font-family: \"Raleway\", sans-serif; } .author-name a:hover { background-color: #306203; } .publish-date { color: rgba(255, 255, 255, 0.5); } .social-icons { display: grid; font-size: 3rem; grid-template-columns: repeat(5, 1fr); grid-auto-flow: column; grid-auto-columns: 1fr; align-items: center; } .first-paragraph::first-letter { font-size: 6rem; color: orangered; float: left; margin-right: 1rem; } .quote { color: #00beef; font-size: 2.4rem; text-align: center; font-family: \"Raleway\", sans-serif; } .quote::before { content: '\" '; } .quote::after { content: ' \"'; } .text-with-images { display: grid; grid-template-columns: 1fr 2fr; column-gap: 3rem; margin-bottom: 3rem; } .lists { list-style-type: none; margin-top: 2rem; } .lists li { margin-bottom: 1.5rem; } .list-title, .list-subtitle { color: #00beef; } .image-wrapper { display: grid; grid-template-columns: 2fr 1fr; grid-template-rows: repeat(3, min-content); gap: 2rem; place-items: center; } .image-1, .image-3 { grid-column: 1 / -1; } @media only screen and (max-width: 720px) { .image-wrapper { grid-template-columns: 1fr; } } @media only screen and (max-width: 600px) { .text-with-images { grid-template-columns: 1fr; } } @media only screen and (max-width: 550px) { .hero-title { font-size: 6rem; } .hero-subtitle, .author, .quote, .list-title { font-size: 1.8rem; } .social-icons { font-size: 2rem; } .text { font-size: 1.6rem; } } /* Extra Small Mobile (≤420px) */ @media only screen and (max-width: 420px) { .hero-title { font-size: 4.5rem; /* Smaller but still impactful */ } } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-06-17 "},"doc_web/ferris_wheel.html":{"url":"doc_web/ferris_wheel.html","title":"摩天轮","keywords":"","body":" 摩天轮 index.html styles.css 摩天轮index.html Ferris Wheel styles.css.wheel { border: 2px solid black; border-radius: 50%; margin-left: 50px; position: absolute; height: 55vw; width: 55vw; max-width: 500px; max-height: 500px; animation-name: wheel; animation-duration: 10s; animation-iteration-count: infinite; animation-timing-function: linear; } .line { background-color: black; width: 50%; height: 2px; position: absolute; top: 50%; left: 50%; transform-origin: 0% 0%; } .line:nth-of-type(2) { transform: rotate(60deg); } .line:nth-of-type(3) { transform: rotate(120deg); } .line:nth-of-type(4) { transform: rotate(180deg); } .line:nth-of-type(5) { transform: rotate(240deg); } .line:nth-of-type(6) { transform: rotate(300deg); } .cabin { background-color: red; width: 20%; height: 20%; position: absolute; border: 2px solid; transform-origin: 50% 0%; animation: cabins 10s ease-in-out infinite; } .cabin:nth-of-type(1) { right: -8.5%; top: 50%; } .cabin:nth-of-type(2) { right: 17%; top: 93.5%; } .cabin:nth-of-type(3) { right: 67%; top: 93.5%; } .cabin:nth-of-type(4) { left: -8.5%; top: 50%; } .cabin:nth-of-type(5) { left: 17%; top: 7%; } .cabin:nth-of-type(6) { right: 17%; top: 7%; } @keyframes wheel { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } } @keyframes cabins { 0% { transform: rotate(0deg); } 25% { background-color: yellow; } 50% { background-color: purple; } 75% { background-color: yellow; } 100% { transform: rotate(-360deg); } } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-06-17 "},"doc_web/penguin.html":{"url":"doc_web/penguin.html","title":"企鹅","keywords":"","body":" 企鹅 index.html styles.css 企鹅index.html Penguin 💜 I CSS styles.css:root { --penguin-face: white; --penguin-picorna: orange; --penguin-skin: gray; } body { background: linear-gradient(45deg, rgb(118, 201, 255), rgb(247, 255, 222)); margin: 0; padding: 0; width: 100%; height: 100vh; overflow: hidden; } .left-mountain { width: 300px; height: 300px; background: linear-gradient(rgb(203, 241, 228), rgb(80, 183, 255)); position: absolute; transform: skew(0deg, 44deg); z-index: 2; margin-top: 100px; } .back-mountain { width: 300px; height: 300px; background: linear-gradient(rgb(203, 241, 228), rgb(47, 170, 255)); position: absolute; z-index: 1; transform: rotate(45deg); left: 110px; top: 225px; } .sun { width: 200px; height: 200px; background-color: yellow; position: absolute; border-radius: 50%; top: -75px; right: -75px; } .penguin { width: 300px; height: 300px; margin: auto; margin-top: 75px; z-index: 4; position: relative; transition: transform 1s ease-in-out 0ms; } .penguin * { position: absolute; } .penguin:active { transform: scale(1.5); cursor: not-allowed; } .penguin-head { width: 50%; height: 45%; background: linear-gradient(45deg, var(--penguin-skin), rgb(239, 240, 228)); border-radius: 70% 70% 65% 65%; top: 10%; left: 25%; z-index: 1; } .face { width: 60%; height: 70%; background-color: var(--penguin-face); border-radius: 70% 70% 60% 60%; top: 15%; } .face.left { left: 5%; } .face.right { right: 5%; } .chin { width: 90%; height: 70%; background-color: var(--penguin-face); top: 25%; left: 5%; border-radius: 70% 70% 100% 100%; } .eye { width: 15%; height: 17%; background-color: black; top: 45%; border-radius: 50%; } .eye.left { left: 25%; } .eye.right { right: 25%; } .eye-lid { width: 150%; height: 100%; background-color: var(--penguin-face); top: 25%; left: -23%; border-radius: 50%; } .blush { width: 15%; height: 10%; background-color: pink; top: 65%; border-radius: 50%; } .blush.left { left: 15%; } .blush.right { right: 15%; } .beak { height: 10%; background-color: var(--penguin-picorna); border-radius: 50%; } .beak.top { width: 20%; top: 60%; left: 40%; } .beak.bottom { width: 16%; top: 65%; left: 42%; } .shirt { font: bold 25px Helvetica, sans-serif; top: 165px; left: 127.5px; z-index: 1; color: #6a6969; } .shirt div { font-weight: initial; top: 22.5px; left: 12px; } .penguin-body { width: 53%; height: 45%; background: linear-gradient(45deg, rgb(134, 133, 133) 0%, rgb(234, 231, 231) 25%, white 67%); border-radius: 80% 80% 100% 100%; top: 40%; left: 23.5%; } .penguin-body::before { content: \"\"; position: absolute; width: 50%; height: 45%; background-color: var(--penguin-skin); top: 10%; left: 25%; border-radius: 0% 0% 100% 100%; opacity: 70%; } .arm { width: 30%; height: 60%; background: linear-gradient(90deg, var(--penguin-skin), rgb(209, 210, 199)); border-radius: 30% 30% 30% 120%; z-index: -1; } .arm.left { top: 35%; left: 5%; transform-origin: top left; transform: rotate(130deg) scaleX(-1); animation: 3s linear infinite wave; } .arm.right { top: 0%; right: -5%; transform: rotate(-45deg); } @keyframes wave { 10% { transform: rotate(110deg) scaleX(-1); } 20% { transform: rotate(130deg) scaleX(-1); } 30% { transform: rotate(110deg) scaleX(-1); } 40% { transform: rotate(130deg) scaleX(-1); } } .foot { width: 15%; height: 30%; background-color: var(--penguin-picorna); top: 85%; border-radius: 50%; z-index: -1; } .foot.left { left: 25%; transform: rotate(80deg); } .foot.right { right: 25%; transform: rotate(-80deg); } .ground { width: 100vw; background: linear-gradient(90deg, rgb(88, 175, 236), rgb(182, 255, 255)); z-index: 3; position: absolute; margin-top: -58px; height: calc(100vh - 300px); } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-06-17 "},"doc_influxdb/":{"url":"doc_influxdb/","title":"InfluxDB","keywords":"","body":" InfluxDB v1.11 文档学习笔记 主要特点 参考资料 InfluxDB v1.11 文档学习笔记主要特点专为时间序列数据编写的高性能数据存储。高速读取和数据压缩。 为您的集群提供高可用性并消除单点故障。 完全用 Go 编写。编译为单个二进制文件，无任何外部依赖。 简单、高性能的写入和查询 HTTP API。 插件支持其他数据提取协议，例如 Graphite、collectd 和 OpenTSDB。 富有表现力的类似 SQL 的查询语言，用于轻松查询聚合数据。 连续查询会自动计算聚合数据，使频繁查询更加高效。 标签让您可以索引系列以实现快速高效的查询。 保留策略可以有效地自动使陈旧数据过期。 参考资料https://docs.influxdata.com/enterprise_influxdb/v1/ Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-06-17 "},"doc_influxdb/concepts.html":{"url":"doc_influxdb/concepts.html","title":"概念","keywords":"","body":"概念Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-06-18 "},"doc_influxdb/concepts_clustering.html":{"url":"doc_influxdb/concepts_clustering.html","title":"集群","keywords":"","body":" InfluxDB 集群 架构概述 数据归属 Meta 节点 Data 节点 最佳服务器数量 Chronograf 集群中的写入 分片组 写入一致性 缓存队列（Hinted handoff） 集群中的查询 InfluxDB 集群架构概述InfluxDB Enterprise 安装包含两组软件进程：数据节点和元节点。集群内的通信如下所示： Meta 数据节点之间通过 TCP 协议和 Raft 共识协议进行通信，默认端口 8089 Meta 节点公开 8091 端口给 influxd-ctl 调用 HTTP API Data 节点通过TCP 协议相互通信，默认端口 8088 Data 节点通过 Meta 节点的 8091 端口的 HTTP API 与其通信 在集群内，所有 Meta 节点都必须与所有其它 Meta 节点通信。所有 Data 节点必须与所有其它 Data 节点和所有 Meta 节点通信 数据归属Meta 节点元节点保存以下所有元数据：集群中的所有节点及其角色 集群中存在的所有数据库和保留策略 所有分片和分片组，以及它们存在于哪些节点上 集群用户及其权限 所有连续查询 元节点将这些数据保存在磁盘上的 Raft 数据库中，该数据库由 BoltDB 支持。默认情况下，Raft 数据库是 /var/lib/influxdb/meta/raft.db。元节点需要/meta目录。Data 节点数据节点保存所有原始时间序列数据和元数据，包括：测量 标签键和值 字段键和值 在磁盘上，数据始终按// 来存储。默认情况下，父目录是 /var/lib/influxdb/data。 数据节点需要的所有四个子目录 /var/lib/influxdb/，包括/meta（具体来说，clients.json 文件）/data、/wal和/hh。最佳服务器数量创建集群时，您需要确定要配置和连接多少个元节点和数据节点。您可以将 InfluxDB Enterprise 视为两个相互通信的独立集群：一个元节点集群和一个数据节点集群。元节点的数量取决于它们需要处理的元节点故障数量，而数据节点的数量则根据您的存储和查询需求进行扩展。Raft 共识协议要求达到法定人数才能执行任何操作，因此元节点数量应始终为奇数。对于几乎所有应用程序来说，3 个元节点都是理想的选择。这样可以保证元节点数量为奇数，从而达到法定人数。此外，即使一个元节点丢失，集群仍可使用剩余的两个元节点运行，直到第三个元节点被替换。额外的元节点会成倍增加通信开销，除非您预计集群会频繁丢失元节点，否则不建议这样做。数据节点保存实际的时间序列数据。运行的数据节点数量至少为 1，并且可以在此基础上扩展。通常，您需要运行的数据节点数量应能被您的复制因子整除。例如，如果您的复制因子为 2，则您需要运行 2、4、6、8、10 等个数据节点。ChronografChronograf是 InfluxData TICK 堆栈的用户界面组件。它使您能够轻松设置和维护基础架构的监控和警报。它通过 HTTP 协议直接与数据节点和元节点通信，这些协议默认绑定到8086数据节点的端口和元节点的端口8091。集群中的写入本节介绍集群中的写入操作。我们将使用包含四个数据节点 A、B、C、D 的集群进行一些示例。假设我们的保留策略为复制因子 2，分片持续时间为 1 天。分片组集群会在分片组中创建分片，以最大化利用数据节点的数量。如果集群中有 N 个数据节点，且复制因子为 X，则每个分片组中会创建 N/X 个分片，并丢弃小数部分。这意味着每天写入的数据都会创建一个新的分片组。每个分片组内会创建 2 个分片。由于复制因子为 2，这两个分片会分别复制到 2 台服务器上。例如，我们有一个 2016-09-19 的分片组，其中包含 1 和 2 两个分片。分片 1 会复制到服务器 A 和 B 上，而分片 2 会复制到服务器 C 和 D上。当一个带有时间戳的写入值传入集群时，集群必须首先确定分片组中的哪个分片应该接收该写入。具体方法是对 measurement + sorted tagset (the metaseries) 进行哈希处理，然后将其分桶到正确的分片中。在 Go 语言中，如下所示：// key is measurement + tagset // shardGroup is the group for the values based on timestamp // hash with fnv and then bucket shard := shardGroup.shards[fnv.New64a(key) % len(shardGroup.Shards)] 这种方案对于确定数据在集群中的位置有多重含义。首先，对于任何给定的元系列，任何给定日期的所有数据都存在于单个分片中，因此仅存在于托管该分片副本的服务器上。其次，一旦创建了分片组，向集群添加新服务器将不会扩展该分片组的写入容量。分片组的复制在创建时就已固定。但是，有一种方法可以在集群扩展时扩展当前分片组（即当前）的写入操作。可以使用 截断当前分片组，使其在当前时间停止 influxd-ctl truncate-shards。这会立即关闭当前分片组，并强制创建一个新的分片组。新的分片组会继承最新的保留策略和数据节点更改，然后将自身适当地复制到新的可用数据节点。运行influxd-ctl truncate-shards help以获取有关该命令的更多信息。写入一致性每个 HTTP API 请求都可以通过 consistency 参数指定一致性级别，该参数影响本次写入多少副本成功后就立刻返回成功。与 Bucket 的副本存储数量配置不冲突。支持 4 种级别:any one quorum all 缓存队列（Hinted handoff）Hinted handoff 本质上是一个基于磁盘的持久队列。一个写往多个副本的请求，如果某个副本宕机，则数据会进入缓存队列。接收节点会为每个无法访问的数据节点（和分片）在磁盘上创建一个单独的队列。可以使用 influx 客户端的 SHOW DIAGNOSTICS 命令来查看当前相关配置。默认最多存7天10G的数据。如果数据节点重启，它会检查缓存队列中是否有待处理的写入操作，并恢复复制。需要注意的是，缓存队列是持久化的，即使进程重启也能继续执行。例如，在升级或维护期间重启活动集群中的节点时，集群中的其他节点会缓存本应写到离线节点的数据，并在该节点恢复可用后进行复制。因此，健康的集群应该在每个数据节点上都留有足够的资源余量，以应对节点宕机后出现的突发缓存写入。恢复的节点需要同时处理稳定状态的流量以及来自其他节点的排队的缓存写入，这意味着在任何超过几秒钟的宕机之后，其写入流量都会出现显著的峰值，直到提示缓存队列耗尽为止。如果一个节点有待处理的指向另一个数据节点的缓存写入操作，并收到发往该节点的写入请求，它会将该写入操作添加到提示切换队列的末尾，而不是尝试直接写入。这确保了数据节点基本按时间顺序接收数据，并避免了在其他节点离线时进行不必要的连接尝试。集群中的查询集群中的查询会根据查询的时间范围和数据的复制因子进行分布。例如，如果保留策略的复制因子为 4，则接收查询的协调数据节点会从存储分片副本的 4 个数据节点中随机选择任意一个来接收查询。假设系统的分片持续时间为一天，那么对于查询覆盖的每一天，协调节点都会选择一个数据节点来接收当天的查询。协调节点尽可能在本地执行并完成查询。如果查询必须扫描多个分片组（在上例中为多天），协调节点会将查询转发到其他节点，以查找其本地没有的分片。查询的转发与扫描其本地数据并行进行。查询会分发到尽可能多的节点，以便对每个分片组进行一次查询。当每个数据节点返回结果时，协调数据节点会将它们合并为最终结果并返回给用户。Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-06-17 "},"doc_influxdb/concepts_key_concepts.html":{"url":"doc_influxdb/concepts_key_concepts.html","title":"关键概念","keywords":"","body":" InfluxDB 关键概念 示例数据 讨论 InfluxDB 关键概念在深入研究 InfluxDB 之前，最好先了解一些数据库的关键概念。本文档介绍了 InfluxDB 的一些关键概念和元素。为了介绍这些关键概念，我们将介绍以下元素在 InfluxDB 中如何协同工作：数据库 (database) 字段键 (field key) 字段集 (field set) 字段值 (field value) 测量 (measurement) 数据点 (point) 保留策略 (retention policy) 系列 (series) 标签键 (tag key) 标签集 (tag set) 标签值 (tag value) 时间戳 (timestamp) 示例数据下一节将引用打印出来的数据。这些数据是虚构的，但代表了 InfluxDB 中可信的设置。它们显示了两位科学家（langstroth和perpetua）在两个地点（位置1和位置2）从 2015 年 8 月 18 日午夜到 2015 年 8 月 18 日凌晨 6:12 统计的蝴蝶和蜜蜂数量。假设这些数据存储在名为的数据库中my_database，并受 autogen 保留策略的约束（更多关于数据库和保留策略的内容将在后面介绍）。姓名： census(measurement) time (timestamp) keybutterflies (field key) keyhoneybees keylocation (tag key) keyscientist 2015-08-18T00:00:00Z 12 (field value) 23 1 (tag value) langstroth 2015-08-18T00:00:00Z 1 30 1 perpetua 2015-08-18T00:06:00Z 11 28 1 langstroth 2015-08-18T00:06:00Z 3 28 1 perpetua 2015-08-18T05:54:00Z 2 11 2 langstroth 2015-08-18T06:00:00Z 1 10 2 langstroth 2015-08-18T06:06:00Z 8 23 2 perpetua 2015-08-18T06:12:00Z 7 22 2 perpetua 讨论现在您已经看到了 InfluxDB 中的一些示例数据，本节将介绍这些数据的含义。InfluxDB 是一个时间序列数据库，因此从我们所有工作的根源开始：时间。上面的数据中有一列名为time——InfluxDB 中的所有数据都有这个列。 time 存储时间戳，并且时间戳显示与特定数据相关的日期和时间（以RFC3339 UTC 表示）。接下来的两列称为 butterflies 和 honeybees，是字段。字段由字段键和字段值组成。 字段键（butterflies和honeybees）是字符串；字段键butterflies告诉我们字段值12-7指的是蝴蝶，而字段键honeybees告诉我们字段值23-22指的是蜜蜂。字段值就是您的数据；它们可以是字符串、浮点数、整数或布尔值。由于 InfluxDB 是一个时间序列数据库，因此字段值始终与时间戳相关联。示例数据中的字段值为：12 23 1 30 11 28 3 28 2 11 1 10 8 23 7 22 在上述数据中，字段键和字段值对的集合构成了一个字段集。以下是示例数据中的所有八个字段集：butterflies = 12 honeybees = 23 butterflies = 1 honeybees = 30 butterflies = 11 honeybees = 28 butterflies = 3 honeybees = 28 butterflies = 2 honeybees = 11 butterflies = 1 honeybees = 10 butterflies = 8 honeybees = 23 butterflies = 7 honeybees = 22 字段是 InfluxDB 数据结构的必需部分——InfluxDB 中的数据不能没有字段。同样需要注意的是，字段不会被索引。 使用字段值作为过滤器的查询必须扫描所有符合查询中其他条件的值。因此，这些查询的性能不如基于标签的查询（下文将详细介绍标签）。通常，字段不应包含常用的元数据。示例数据中的最后两列称为location和scientist，是标签。标签由标签键和标签值组成。两者标签键和标签值以字符串形式存储，并记录元数据。样本数据中的标签键为location和scientist。标签键location有两个标签值：1和2。标签键scientist也有两个标签值：langstroth和perpetua。在上述数据中，标签集是所有标签键值对的不同组合。样本数据中的四个标签集分别为：location = 1，scientist = langstroth location = 2，scientist = langstroth location = 1，scientist = perpetua location = 2，scientist = perpetua 标签是可选的。您的数据结构中并非必须包含标签，但通常情况下，使用标签是个好主意，因为与字段不同，标签是被索引的。这意味着对标签的查询速度更快，并且标签非常适合存储常用的元数据。避免使用以下保留键：_field _measurement time 如果保留键作为标签或字段键包含在内，则相关点将被丢弃。测量(measurement)是持有标签、字段和时间列的容器，测量名称是对存储在关联字段中的数据的描述。测量名称是字符串，对于任何 SQL 用户来说，测量在概念上类似于表。示例数据中测量名称是census。单个测量可以属于不同的保留策略。保留策略描述了 InfluxDB 保留数据的时间（DURATION）以及集群中存储的数据副本数量（REPLICATION）。如果您想了解更多关于保留策略的信息，请参阅数据库管理。复制因子对于单节点实例不起作用现在来讨论一下系列(series)。在 InfluxDB 中，系列是共享测量、标签集和字段键的点的集合。上面的数据由八个系列组成： Series Measurement Tag set Field key 1 census location=1, scientist=langstroth butterflies 2 census location=2, scientist=langstroth butterflies 3 census location=1, scientist=perpetua butterflies 4 census location=2, scientist=perpetua butterflies 5 census location=1, scientist=langstroth honeybees 6 census location=2, scientist=langstroth honeybees 7 census location=1, scientist=perpetua honeybees 8 census location=2, scientist=perpetua honeybees 一个点表示一条包含四个组成部分的数据记录：测量、标签集、字段集和时间戳。一个点由其序列和时间戳唯一标识。 例如，这里有一个点：name: census ----------------- time butterflies honeybees location scientist 2015-08-18T00:00:00Z 1 30 1 perpetua 此示例中的点是系列 3 和 7 的一部分，由测量（census）、标签集（location = 1、scientist = perpetua）、字段集（butterflies = 1、honeybees = 30）和时间戳 2015-08-18T00:00:00Z 定义。我们刚刚介绍的所有内容都存储在数据库中 - 示例数据就在数据库中my_database。InfluxDB数据库类似于传统的关系数据库，它充当用户、保留策略、持续查询以及时间序列数据的逻辑容器。有关这些主题的更多信息，请参阅身份验证和授权以及持续查询。数据库可以支持多个用户、连续查询、保留策略和测量。InfluxDB 是一个无模式数据库，这意味着您可以随时轻松添加新的测量、标签和字段。它旨在让时间序列数据处理变得无比便捷。Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-06-18 "},"doc_influxdb/concepts_startup_process.html":{"url":"doc_influxdb/concepts_startup_process.html","title":"启动过程","keywords":"","body":" InfluxDB 启动过程 子系统和服务 TSDBStore: TSDB存储 Monitor: 监控 Cluster: 集群 Precreator: 预创建 Snapshotter: 快照 Continuous Query: 连续查询 Announcer: 广播 Retention: 保留 Stats: 统计 Anti-entropy: 反熵 HTTP API: HTTP 接口 InfluxDB 启动过程启动时，InfluxDB Enterprise 按以下顺序启动所有子系统和服务：TSDBStore: TSDB存储 Monitor: 监控 Cluster: 集群 Precreator: 预创建 Snapshotter: 快照 Continuous Query: 连续查询 Announcer: 广播 Retention: 保留 Stats: 统计 Anti-entropy: 反熵 HTTP API: HTTP 接口 子系统是一系列相关服务的集合，它们作为更大整体的一部分进行管理。服务是提供特定功能的进程。子系统和服务TSDBStore: TSDB存储TSDBStore 子系统启动并管理 TSM 存储引擎。这包括点写入（写入）、读取（查询）和缓存队列 (HH) 等服务。TSDBSTore 首先打开所有分片，并将预写日志 (WAL) 数据加载到内存写缓存中。如果influxd之前已完全关闭，则不会有任何 WAL 数据。然后，它会加载每个分片索引的一部分。索引版本和启动时间 如果使用inmem索引，InfluxDB 会将所有分片索引加载到内存中，这可能需要一些时间，具体取决于数据库中的系列数量。如果使用tsi1索引，InfluxDB 只会将热分片索引（最近的分片或当前正在写入的分片）加载到内存中，并将冷分片索引存储在磁盘上。使用tsi1索引可以缩短启动时间。 InfluxDB 1.8+ 默认使用 tsi1 索引Monitor: 监控监控服务向 InfluxDB 提供有关其自身的统计和诊断信息。这些信息有助于数据库故障排除和性能分析。Cluster: 集群集群服务提供在 InfluxDB Enterprise v1.8 集群上运行的 InfluxDB OSS v1.8 接口的实现。Precreator: 预创建预创建服务会在需要分片之前创建它们。这确保了在新的时间序列数据到达之前，必要的分片已经存在，并且写入吞吐量不会受到新分片创建的影响。Snapshotter: 快照快照服务会定期创建 InfluxDB Enterprise 元数据的快照。Continuous Query: 连续查询连续查询 (CQ) 子系统管理所有 InfluxDB CQ。Announcer: 广播服务向 Meta 节点广播数据节点的状态。Retention: 保留保留服务强制执行保留策略 并在数据过期时删除数据。Stats: 统计统计服务监控集群级别的统计数据。Anti-entropy: 反熵反熵 (AE) 子系统负责协调分片之间的差异。HTTP API: HTTP 接口InfluxDB HTTP API 服务提供面向公众的接口，用于与 InfluxDB Enterprise 以及 InfluxDB Enterprise 集群内使用的内部接口进行交互。Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-06-18 "},"doc_influxdb/administration.html":{"url":"doc_influxdb/administration.html","title":"运维管理","keywords":"","body":"运维管理Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-06-18 "},"doc_influxdb/administration_configure.html":{"url":"doc_influxdb/administration_configure.html","title":"配置管理","keywords":"","body":"配置管理Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-06-18 "},"doc_influxdb/administration_configure_clusters.html":{"url":"doc_influxdb/administration_configure_clusters.html","title":"配置集群","keywords":"","body":" 配置集群 使用配置文件 创建配置文件 使用配置文件启动进程 环境变量 GOMAXPROCS环境变量 配置集群本页包含有关配置 InfluxDB Enterprise 集群的常规信息。有关配置设置的完整列表和说明，请参阅：配置 Data 节点 配置 Meta 节点 使用配置文件显示默认配置 以下命令打印出 TOML 格式的配置，其中所有可用选项均设置为其默认值。Meta 节点配置influxd-meta config Data 节点配置influxd config 创建配置文件在 POSIX 系统上，通过将命令的输出重定向到文件来生成新的配置文件。新的元节点配置文件：influxd-meta config > /etc/influxdb/influxdb-meta-generated.conf 新的数据节点配置文件：influxd config > /etc/influxdb/influxdb-generated.conf 使用该选项生成新配置文件时，可以使用 -config 参数来保留旧配置文件中的自定义设置。influxd config -config /etc/influxdb/influxdb.conf.old > /etc/influxdb/influxdb.conf.new 使用配置文件启动进程有两种方法可以使用自定义配置文件启动元或数据进程。使用 -config 将进程指向所需的配置文件。 要启动元节点进程，请使用/etc/influxdb/influxdb-meta-generate.conf：influxd-meta -config /etc/influxdb/influxdb-meta-generate.conf 要启动数据节点进程，请使用以下命令/etc/influxdb/influxdb-generated.conf：influxd -config /etc/influxdb/influxdb-generated.conf 将环境变量设置 INFLUXDB_CONFIG_PATH 为配置文件的路径并启动该进程。 要设置环境变量并使用配置文件路径 INFLUXDB_CONFIG_PATH 启动数据进程：INFLUXDB_CONFIG_PATHexport INFLUXDB_CONFIG_PATH=/root/influxdb.generated.conf echo $INFLUXDB_CONFIG_PATH /root/influxdb.generated.conf influxd 如果设置，-config 命令行路径将覆盖任何环境变量路径。如果您未提供配置文件，InfluxDB 将使用内部默认配置(相当于使用 influxd config和influxd-meta config的输出)使用配置文件 (influxdb.conf) 和环境变量配置 InfluxDB。每个配置设置的默认值均显示在文档中。注释掉的配置选项将使用默认值。具有持续时间值的配置设置支持以下持续时间单位：ns （纳秒） us或µs （微秒） ms （毫秒） s （秒） m （分钟） h （小时） d （天） w （周） 环境变量所有配置选项都可以在配置文件或环境变量中指定。环境变量会覆盖配置文件中的等效选项。如果配置文件或环境变量中均未指定某个配置选项，InfluxDB 将使用其内部默认配置。在以下部分中，我们将在配置设置的描述中命名相关的环境变量。环境变量可以在/etc/default/influxdb-meta和/etc/default/influxdb设置。注意： 要设置或覆盖允许多种配置的配置节中的设置（任何[[...]]在标题中带有双括号 ( ) 的节都支持多种配置），所需的配置必须按序号指定。例如，对于第一组[[graphite]]环境变量，在环境变量中，在配置设置名称前加上相应的位置编号（在本例中为：0）INFLUXDB_GRAPHITE_0_BATCH_PENDING INFLUXDB_GRAPHITE_0_BATCH_SIZE INFLUXDB_GRAPHITE_0_BATCH_TIMEOUT INFLUXDB_GRAPHITE_0_BIND_ADDRESS INFLUXDB_GRAPHITE_0_CONSISTENCY_LEVEL INFLUXDB_GRAPHITE_0_DATABASE INFLUXDB_GRAPHITE_0_ENABLED INFLUXDB_GRAPHITE_0_PROTOCOL INFLUXDB_GRAPHITE_0_RETENTION_POLICY INFLUXDB_GRAPHITE_0_SEPARATOR INFLUXDB_GRAPHITE_0_TAGS INFLUXDB_GRAPHITE_0_TEMPLATES INFLUXDB_GRAPHITE_0_UDP_READ_BUFFER 对于配置文件中的第 N 个 Graphite 配置，相关的环境变量将采用以下形式INFLUXDBGRAPHITE(N-1)_BATCH_PENDING。对于配置文件的每个部分，编号从零重新开始。GOMAXPROCS环境变量GOMAXPROCS无法使用 InfluxDB 配置文件进行设置。只能将其设置为环境变量。 GOMAXPROCS Go语言环境变量可以 用来设置可以同时执行的最大CPU数量。GOMAXPROCS 的默认值是程序启动时可见的 CPU 数量 （基于操作系统对 CPU 的定义）。对于 32 核的机器，该值为 32。您可以覆盖此值，使其小于最大值。如果您在同一台机器上同时运行 InfluxDB 和其他进程，并且希望确保数据库不会对这些进程产生负面影响，那么此功能非常有用。设置GOMAXPROCS=1会消除所有并行化。Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-06-18 "},"doc_influxdb/administration_configure_data_nodes.html":{"url":"doc_influxdb/administration_configure_data_nodes.html","title":"配置 Data 节点","keywords":"","body":" 配置 Data 节点 Data 节点配置设置 Global 全局设置 reporting-disabled bind-address hostname gossip-frequency compact-series-file v1.11.4+ Enterprise license 企业许可证 license-key license-path Meta node Meta节点设置 dir meta-tls-enabled meta-insecure-tls meta-auth-enabled meta-internal-shared-secret retention-autocreate logging-enabled password-hash ensure-fips Data 数据 dir wal-dir trace-logging-enabled query-log-enabled query-log-path wal-fsync-delay ingress-metric-by-measurement-enabled ingress-metric-by-login-enabled TSM引擎的数据设置 cache-max-memory-size cache-snapshot-memory-size cache-snapshot-write-cold-duration max-concurrent-compactions compact-throughput compact-throughput-burst compact-full-write-cold-duration index-version inmem 索引设置 max-series-per-database max-values-per-tag TSI（tsi1）指数设置 max-index-log-file-size series-id-set-cache-size Cluster 集群 dial-timeout pool-max-idle-time pool-max-idle-streams allow-out-of-order-writes shard-reader-timeout https-enabled https-certificate https-private-key https-insecure-tls cluster-tracing write-timeout max-concurrent-queries max-concurrent-deletes query-timeout log-queries-after log-timedout-queries max-select-point max-select-series max-select-buckets termination-query-log Retention 保留策略 enabled check-interval Hinted Handoff 缓存队列 batch-size max-writes-pending dir enabled max-size max-age retry-concurrency retry-rate-limit retry-interval retry-max-interval purge-interval Anti-Entropy 反熵 enabled check-interval max-fetch max-sync auto-repair-missing Shard precreation 分片预创建 enabled check-interval advance-period Monitor 监控 store-enabled store-database store-interval remote-collect-interval HTTP endpoints HTTP端点 enabled flux-enabled bind-address auth-enabled realm log-enabled suppress-write-log access-log-path access-log-status-filters write-tracing pprof-enabled https-enabled https-certificate https-private-key shared-secret max-body-size max-row-limit max-connection-limit unix-socket-enabled bind-socket max-concurrent-write-limit max-enqueued-write-limit enqueued-write-timeout Logging 日志 format level suppress-logo Subscriber 订阅 enabled http-timeout insecure-skip-verify ca-certs write-concurrency write-buffer-size total-buffer-bytes Graphite Graphite协议 Collectd CollectD协议 OpenTSDB OpenTSDB协议 UDP UDP协议 Continuous queries 连续查询 enabled log-enabled query-stats-enabled run-interval TLS TLS加密 min-version max-version Flux Query controls Flux查询 query-concurrency query-initial-memory-bytes query-max-memory-bytes total-max-memory-bytes query-queue-size 配置 Data 节点Data 节点配置设置 Global Enterprise license [enterprise] Meta node [meta] Data [data] Cluster [cluster] (includes InfluxQL query controls) Retention [retention] Hinted Handoff [hinted-handoff] Anti-Entropy [anti-entropy] Shard precreation [shard-precreation] Monitor [monitor] HTTP endpoints [http] Logging [logging] Subscriber [subscriber] Graphite [graphite] Collectd [collectd] OpenTSDB [opentsdb] UDP [udp] Continuous queries [continuous-queries] TLS [tls] Flux Query controls [flux-controller] Data 节点配置设置系统为每个配置文件设置都设置了内部默认值。使用influxd config命令查看默认设置。本地配置文件 ( /etc/influxdb/influxdb.conf) 会覆盖所有内部默认值，但配置文件无需包含所有配置设置。从 1.0.1 版本开始，本地配置文件中的大多数设置均已被注释掉。所有注释掉的设置将由内部默认值决定。Global 全局设置reporting-disabled每 24 小时会将使用情况数据报告至 usage.influxdata.com。报告数据包含随机 ID、操作系统、架构、版本、系列数量以及其他使用情况数据。用户数据库的数据不会传输。将此选项更改为 true 可禁用报告功能。默认值: false bind-addressRPC服务用于节点间通信和备份与恢复的TCP绑定地址。默认值: \":8088\" 环境变量: INFLUXDB_BIND_ADDRESS hostname数据节点的主机名。该主机名必须能够被集群中的所有其他节点解析。默认值: \"localhost\" 环境变量: INFLUXDB_HOSTNAME gossip-frequency节点的内部状态更新至集群的频率。默认值: \"3s\" 环境变量: INFLUXDB_GOSSIP_FREQUENCY compact-series-file v1.11.4+确定是否应在启动时压缩 series-file。如果是true，则 InfluxDB 会在 influxd 服务启动之前运行 influxd_inspect -compact-series-file。默认值: false 系列文件压缩 系列文件存储在InfluxDB 数据目录_series内的目录 中。默认值：。/var/lib/data//_series 在启动时压缩系列文件时： 如果任何系列文件损坏，数据节点上的influx_inspect或influxd进程可能无法启动。在这两种情况下，请在重启数据库之前删除系列文件目录。InfluxDB 会在重启时自动重新生成必要的系列目录和文件。 要在启动数据库之前检查系列文件是否损坏，请 在数据库离线时运行 influx_inspect verify-seriesfile 命令。 如果系列文件很大（20+ GB），则在启动数据库之前删除系列文件目录可能会更快。Enterprise license 企业许可证[enterprise] 配置包含了 Meta 节点使用 InfluxDB 企业授权注册的配置license-key在InfluxPortal上为您创建的许可证密钥。元节点通过端口 80 或 443 将许可证密钥传输至portal.influxdata.com，并接收一个临时的 JSON 许可证文件。服务器会在本地缓存该许可证文件。如果没有有效的许可证文件，数据进程将只能运行有限时间。如果您的服务器无法与https://portal.influxdata.com通信，则必须使用license-path设置离线授权。默认值: \"\" 环境变量: INFLUXDB_ENTERPRISE_LICENSE_KEY license-path您从 InfluxData 收到的永久 JSON 许可证文件的本地路径，适用于无法访问互联网的实例。如果没有有效的许可证文件，数据处理将只能运行有限的时间。如果需要许可证文件，请联系sales@influxdb.com 。许可证文件应保存在集群中的每台服务器上，包括元节点、数据节点和企业节点。该文件包含 JSON 格式的许可证，并且必须可供influxdb用户读取。集群中的每台服务器都会独立验证其许可证。默认值: \"\" 环境变量: INFLUXDB_ENTERPRISE_LICENSE_PATH Meta node Meta节点设置[meta] Data 节点如何 Meta 节点交互相关的设置。dir存储集群元数据的目录。默认值: \"/var/lib/influxdb/meta\" 环境变量: INFLUXDB_META_DIR meta-tls-enabled连接元节点时是否使用 TLS默认值: false 环境变量: INFLUXDB_META_META_TLS_ENABLED meta-insecure-tls允许与元节点建立不安全的 TLS 连接。这在使用自签名证书进行测试时很有用。默认值: false 环境变量: INFLUXDB_META_META_INSECURE_TLS meta-auth-enabled该配置必须与 Meta 节点的相同配置设置一样的值。 开启 JWT 认证，详见参数 meta-internal-shared-secret默认值: false 环境变量: INFLUXDB_META_META_AUTH_ENABLED meta-internal-shared-secret该配置必须与 Meta 节点的相同配置设置一样的值。 InfluxDB 节点之间 JWT 身份验证的内部 API 使用的共享密钥。默认值: \"\" 环境变量: INFLUXDB_META_META_INTERNAL_SHARED_SECRET retention-autocreate自动创建保策略，默认 RP 持续时间无限，分片组持续时间7天，复制因子为集群中的数据节点数默认值: true 环境变量: INFLUXDB_META_RETENTION_AUTOCREATE logging-enabled是否打印 Meta 服务的日志默认值: true 环境变量: INFLUXDB_META_LOGGING_ENABLED password-hash该配置必须与 Meta 节点的相同配置设置一样的值。 配置密码哈希算法。支持的选项有：（bcrypt默认）、pbkdf2-sha256、 和pbkdf2-sha512。 有关详细配置信息，请参阅 meta.password-hash。默认值: bcrypt 环境变量: INFLUXDB_META_PASSWORD_HASH ensure-fips启动时是否检查 Influx 数据平台是否符合 FIPS 安全标准默认值: false 环境变量: INFLUXDB_META_ENSURE_FIPS Data 数据[data] 控制 InfluxDB 实际分片数据的位置以及如何从 WAL 压缩数据。dirTSM 存储引擎存储 TSM（读优化）文件的目录。默认值: \"/var/lib/influxdb/data\" 环境变量: INFLUXDB_DATA_DIR wal-dirTSM 存储引擎存储 WAL（写优化）文件的目录。默认值: \"/var/lib/influxdb/wal\" 环境变量: INFLUXDB_DATA_WAL_DIR trace-logging-enabled跟踪日志记录提供有关 TSM 引擎的更详细输出。启用此功能可以为调试 TSM 引擎问题提供更有用的输出。默认值: false 环境变量: INFLUXDB_DATA_TRACE_LOGGING_ENABLED query-log-enabled是否应在执行前记录查询。这对于故障排除非常有用，但会记录查询中包含的任何敏感数据。默认值: true 环境变量: INFLUXDB_DATA_QUERY_LOG_ENABLED query-log-path查询日志文件的绝对路径。默认值为\"\"（查询不会记录到文件中）。 查询日志记录支持基于 SIGHUP 的日志轮换。 下面是一个 logrotate 配置示例:/var/log/influxdb/queries.log { rotate 5 daily compress missingok notifempty create 644 root root postrotate /bin/kill -HUP `pgrep -x influxd` endscript } 默认值: \"\" wal-fsync-delay写入操作在 fsync 之前等待的时间。使用大于 0 的持续时间可以批量执行多个 fsync 调用。这对于速度较慢的磁盘或遇到 WAL 写入争用时非常有用。值为 0s 时，每次写入 WAL 时都会进行 fsync。对于非 SSD 磁盘，InfluxData 建议使用介于 0ms 到 100ms 之间的值。默认值: \"0s\" 环境变量: INFLUXDB_DATA_WAL_FSYNC_DELAY ingress-metric-by-measurement-enabled收集每次测量的点、值和新写入序列的统计信息。指标按数据节点收集。这些指标可以通过/debug/vars端点访问，如果启用，也可以在_internal数据库中访问。默认值: false 环境变量: INFLUXDB_DATA_INGRESS_METRIC_BY_MEASUREMENT_ENABLED ingress-metric-by-login-enabled收集每次登录时点、值和新写入序列的统计信息。指标按数据节点收集。这些指标可以通过/debug/vars端点访问，_internal如果启用，也可以在数据库中访问。默认值: false 环境变量: INFLUXDB_DATA_INGRESS_METRIC_BY_LOGIN_ENABLED TSM引擎的数据设置cache-max-memory-size分片缓存在开始拒绝写入之前可以达到的最大大小（以字节为单位）。 如果遇到 cache maximum memory size exceeded 错误，请考虑增加此值。默认值: 1000000000 环境变量: INFLUXDB_DATA_CACHE_MAX_MEMORY_SIZE cache-snapshot-memory-sizeTSM 引擎将对缓存进行快照并将其写入 TSM 文件以释放内存的字节大小。默认值: 26214400 环境变量: INFLUXDB_DATA_CACHE_SNAPSHOT_MEMORY_SIZE cache-snapshot-write-cold-duration如果分片尚未收到写入或删除，TSM 引擎将对缓存进行快照并将其写入新的 TSM 文件的时间长度。默认值: \"10m\" 环境变量: INFLUXDB_DATA_CACHE_SNAPSHOT_WRITE_COLD_DURATION max-concurrent-compactions一次可运行的最大并发完整压缩和层级压缩数量。设置为 0 时使用 50% 的 runtime.GOMAXPROCS(0)，即 50% CPU。此设置不适用于缓存快照。默认值: 0 环境变量: INFLUXDB_DATA_CACHE_MAX_CONCURRENT_COMPACTIONS compact-throughputTSM 压缩每秒写入磁盘的最大字节数。请注意，允许短时间突发写入，但可能存在更大的值，具体值由 compact-throughput-burst 设定。默认值: 50331648 环境变量: INFLUXDB_DATA_COMPACT_THROUGHPUT compact-throughput-burstTSM 压缩在短暂突发情况下每秒写入磁盘的最大字节数。默认值: 50331648 环境变量: INFLUXDB_DATA_COMPACT_THROUGHPUT_BURST compact-full-write-cold-duration如果尚未收到写入或删除，则压缩分片中所有 TSM 和 TSI 文件的持续时间。默认值: \"4h\" 环境变量: INFLUXDB_DATA_COMPACT_FULL_WRITE_COLD_DURATION index-version用于新分片的分片索引类型。默认值 (inmem) 表示启动重新创建 in-memory 索引。值为 tsi1 时，将使用支持高基数数据集的磁盘索引。默认值: \"inmem\" 环境变量: INFLUXDB_DATA_INDEX_VERSION inmem 索引设置max-series-per-database每个数据库的 series 最大数量，0 为不限制。 如果某个点导致数据库中的系列数量超过 max-series-per-database，则 InfluxDB 将不会写入该点，并返回 500以下错误：{\"error\":\"max series per database exceeded: \"} 对于数量超过此限制的现有数据库将继续接受对现有 series 的写入，但会创建新 series 的写入将失败。默认值: 1000000 环境变量: INFLUXDB_DATA_MAX_SERIES_PER_DATABASE max-values-per-tag每个标签键允许的最大标签值数量，0 为不限制。 任何标签值超出此限制时将继续接受写入，但创建新标签值的写入将失败。默认值: 10000 环境变量: INFLUXDB_DATA_MAX_VALUES_PER_TAG TSI（tsi1）指数设置max-index-log-file-size索引预写日志 (WAL) 文件压缩成索引文件的阈值（以字节为单位）。较小的大小将导致日志文件压缩得更快，从而降低堆使用率，但会降低写入吞吐量。较大的大小将减少压缩频率，在内存中存储更多序列，并提供更高的写入吞吐量。有效的大小后缀为k、m、 或g（不区分大小写，1024 = 1k）。没有大小后缀的值以字节为单位。默认值: 1048576 环境变量: INFLUXDB_DATA_MAX_INDEX_LOG_FILE_SIZE series-id-set-cache-sizeTSI 索引中用于存储先前计算的序列结果的内部缓存大小。缓存结果将从缓存中快速返回，而无需在执行后续查询时重新计算。将此值设置为0将禁用缓存，这可能会导致查询性能问题。仅当已知数据库所有测量中常用的标签键值谓词集合大于 100 时，才应增加此值。增加缓存大小可能会导致堆使用率增加。默认值: 100 环境变量: INFLUXDB_DATA_SERIES_ID_SET_CACHE_SIZE Cluster 集群[cluster] 数据节点如何相互通信、如何跨分片共享数据以及如何管理 InfluxQL 查询相关的设置。 InfluxDB Enterprise 集群使用远程过程调用 (RPC) 进行节点间通信。RPC 连接池管理流连接并高效利用系统资源。InfluxDB 数据节点通过单个 TCP 连接多路复用 RPC 流，以避免频繁建立和销毁 TCP 连接以及耗尽临时端口的开销。通常，一个数据节点会与其他每个数据节点建立单个持久 TCP 连接来执行大多数 RPC 请求。在特殊情况下，例如复制分片时，可能会使用一次性 TCP 连接。dial-timeoutMeta 节点在尝试连接到一个 Data 节点的超时。此设置仅适用于查询。默认值: \"1s\" 环境变量: INFLUXDB_CLUSTER_DIAL_TIMEOUT pool-max-idle-time连接到其他数据节点的 TCP 连接在连接池中保持空闲的最长时间。当连接空闲时间超过指定时长时，系统会回收（退役或回收）非活动连接，以防止连接池中充满非活动连接。回收空​​闲连接可以最大限度地减少非活动连接数量，降低系统负载，并防止系统故障。默认值: \"60s\" 环境变量: INFLUXDB_CLUSTER_POOL_MAX_IDLE_TIME pool-max-idle-streams两个节点之间空闲池中保留的最大空闲 RPC 流连接数。发出新的 RPC 请求时，系统会临时从空闲池中拉取一个连接，使用后再归还。如果空闲池已满，且不再需要某个流连接，系统将关闭该流连接，并将资源释放。活动流的数量可以超过最大空闲池连接数，但在释放后不会归还到空闲池中。创建流的操作相对来说成本较低，因此更改此值不太可能显著提升两个节点之间的性能。默认值: 100 环境变量: INFLUXDB_CLUSTER_POOL_MAX_IDLE_STREAMS allow-out-of-order-writes写入操作将按接收顺序处理。这意味着，如果某个分片的提示切换 (HH) 队列中存在任何数据点，则所有传入的数据点都必须进入 HH 队列。 如果为 true，写入操作的处理顺序可能与接收顺序不同。这可以减少清空 HH 队列所需的时间，并提高恢复期间的吞吐量，但可能会导致点被覆盖。默认值: false 环境变量: INFLUXDB_CLUSTER_ALLOW_OUT_OF_ORDER shard-reader-timeout分片读取器上设置的默认超时时间。查询连接必须在此时间后返回响应，否则系统将返回错误。默认值: \"0\" 环境变量: INFLUXDB_CLUSTER_SHARD_READER_TIMEOUT https-enabledData 节点间通信启用 https默认值: false 环境变量: INFLUXDB_CLUSTER_HTTPS_ENABLED https-certificatehttps 证书位置默认值: \"\" 环境变量: INFLUXDB_CLUSTER_HTTPS_CERTIFICATE https-private-keyhttps 私钥位置默认值: \"\" 环境变量: INFLUXDB_CLUSTER_HTTPS_PRIVATE_KEY https-insecure-tls数据节点通过 HTTPS 相互通信时是否跳过证书验证。这在使用自签名证书进行测试时很有用。默认值: false 环境变量: INFLUXDB_CLUSTER_HTTPS_INSECURE_TLS cluster-tracing启用集群跟踪日志记录。设置为true可启用集群通信日志记录。启用此设置可验证数据节点之间的连接问题。默认值: false 环境变量: INFLUXDB_CLUSTER_CLUSTER_TRACING write-timeout写入超时默认值: \"10s\" 环境变量: INFLUXDB_CLUSTER_WRITE_TIMEOUT max-concurrent-queries最大查询并发默认值: \"0\" 环境变量: INFLUXDB_CLUSTER_MAX_CONCURRENT_QUERIES max-concurrent-deletes最大删除并发默认值: 1 环境变量: INFLUXDB_CLUSTER_MAX_CONCURRENT_DELETES query-timeout查询超时默认值: \"0s\" 环境变量: INFLUXDB_CLUSTER_QUERY_TIMEOUT log-queries-after查询被记录为慢查询的时间阈值。默认值: \"0s\" 环境变量: INFLUXDB_CLUSTER_LOG_QUERIES_AFTER log-timedout-queries记录超时被终止的查询默认值: false 环境变量: INFLUXDB_CLUSTER_LOG_TIMEDOUT_QUERIES max-select-point最大查询点数默认值: 0 环境变量: INFLUXDB_CLUSTER_MAX_SELECT_POINT max-select-series最大查询系列数默认值: 0 环境变量: INFLUXDB_CLUSTER_MAX_SELECT_SERIES max-select-buckets最大用于聚合的桶数默认值: 0 环境变量: INFLUXDB_CLUSTER_MAX_SELECT_BUCKETS termination-query-log终止服务时打印当前正在运行的查询默认值: false 环境变量: INFLUXDB_CLUSTER_TERMINATION_QUERY_LOG Retention 保留策略[retention] 控制旧数据清理的保留策略的执行enabled是否启用默认值: true 环境变量: INFLUXDB_RETENTION_ENABLED check-interval检查间隔默认值: \"30m0s\" 环境变量: INFLUXDB_RETENTION_CHECK_INTERVAL Hinted Handoff 缓存队列[hinted-handoff] 控制缓存队列，当数据节点无法访问时，该队列允许数据节点临时缓存发往另一个数据节点的写入batch-size单个请求中写入分片的最大字节数。默认值: 512000 环境变量: INFLUXDB_HINTED_HANDOFF_BATCH_SIZE max-writes-pending缓存队列允许的最大待处理数默认值: 1024 环境变量: INFLUXDB_HINTED_HANDOFF_MAX_WRITES_PENDING dir缓存队列存储路径默认值: \"/var/lib/influxdb/hh\" 环境变量: INFLUXDB_HINTED_HANDOFF_DIR enabled是否启用缓存队列默认值: true 环境变量: INFLUXDB_HINTED_HANDOFF_ENABLED max-size最大容量默认值: 10737418240 环境变量: INFLUXDB_HINTED_HANDOFF_MAX_SIZE max-age最大年龄默认值: \"168h0m0s\" 环境变量: INFLUXDB_HINTED_HANDOFF_MAX_AGE retry-concurrency往一个节点写入块的并发数默认值: 20 环境变量: INFLUXDB_HINTED_HANDOFF_RETRY_CONCURRENCY retry-rate-limit重试速率限制默认值: 0 环境变量: INFLUXDB_HINTED_HANDOFF_RETRY_RATE_LIMIT retry-interval重试间隔，存在指数退避，一直增加至 retry-max-interval默认值: \"1s\" 环境变量: INFLUXDB_HINTED_HANDOFF_RETRY_INTERVAL retry-max-interval重试失败指数退避最大间隔默认值: \"200s\" 环境变量: INFLUXDB_HINTED_HANDOFF_RETRY_MAX_INTERVAL purge-interval缓存队列过期清理间隔默认值: \"1m0s\" 环境变量: INFLUXDB_HINTED_HANDOFF_PURGE_INTERVAL Anti-Entropy 反熵[anti-entropy] 控制分片的复制和修复，以确保数据节点包含应有的分片数据enabled是否启用默认值: false 环境变量: INFLUXDB_ANTI_ENTROPY_ENABLED check-interval检查间隔默认值: \"5m\" 环境变量: INFLUXDB_ANTI_ENTROPY_CHECK_INTERVAL max-fetch单个数据节点可以并行复制或修复的最大分片数默认值: 10 环境变量: INFLUXDB_ANTI_ENTROPY_MAX_FETCH max-sync最大同步并发数默认值: 1 环境变量: INFLUXDB_ANTI_ENTROPY_MAX_SYNC auto-repair-missing自动修复缺失分片默认值: true 环境变量: INFLUXDB_ANTI_ENTROPY_AUTO_REPAIR_MISSING Shard precreation 分片预创建[shard-precreation] 控制分片的预创建，使其在数据到达之前可用。只有创建后开始时间和结束时间都在未来时间的分片才会被创建。永远不会预先创建完全或部分处于过去时间的分片。enabled是否启用默认值: true 环境变量: INFLUXDB_SHARD_PRECREATION_ENABLED check-interval检查间隔默认值: \"10m\" 环境变量: INFLUXDB_SHARD_PRECREATION_CHECK_INTERVAL advance-period在分片组结束时间之前创建其后继组的提前时间段。默认值: \"30m\" 环境变量: INFLUXDB_SHARD_PRECREATION_ADVANCE_PERIOD Monitor 监控[monitor] 默认情况下，InfluxDB 会将系统监控数据写入 _internal 数据库。如果该数据库不存在，InfluxDB 会自动创建。_internal 数据库的保留策略为 7 天。要更改默认的 7 天保留策略，您必须创建该数据库。对于 InfluxDB Enterprise 生产系统，InfluxData 建议包含一个专用的 InfluxDB (OSS) 监控实例来监控 InfluxDB Enterprise 集群节点。在专用的 InfluxDB 监控实例上进行设置store-enabled = false以避免潜在的性能和存储问题。 在每个 InfluxDB 集群节点上，安装一个 Telegraf 输入插件和 Telegraf 输出插件，配置为将数据报告给专用的 InfluxDB 监控实例。 store-enabled是否存储监控数据默认值: true 环境变量: INFLUXDB_MONITOR_STORE_ENABLED store-database存储数据库默认值: \"_internal\" 环境变量: INFLUXDB_MONITOR_STORE_DATABASE store-interval存储间隔默认值: \"10s\" 环境变量: INFLUXDB_MONITOR_STORE_INTERVAL remote-collect-interval收集间隔默认值: \"10s\" 环境变量: INFLUXDB_MONITOR_REMOTE_COLLECT_INTERVAL HTTP endpoints HTTP端点[http] 控制如何配置 HTTP 端点。这些是将数据传入和传出 InfluxDB 的主要机制。enabled是否启用默认值: true 环境变量: INFLUXDB_HTTP_ENABLED flux-enabled是否启用 flux 语法查询默认值: false 环境变量: INFLUXDB_HTTP_FLUX_ENABLED bind-address监听地址默认值: \":8086\" 环境变量: INFLUXDB_HTTP_BIND_ADDRESS auth-enabled是否开启认证默认值: false 环境变量: INFLUXDB_HTTP_AUTH_ENABLED realm发出基本授权质询时发回的默认领域默认值: \"InfluxDB\" 环境变量: INFLUXDB_HTTP_REALM log-enabled是否启用默认值: true 环境变量: INFLUXDB_HTTP_LOG_ENABLED suppress-write-log抑制写入日志，降低日志记录量默认值: false 环境变量: INFLUXDB_HTTP_SUPPRESS_WRITE_LOG access-log-path日志路径，未指定或者无法访问时写入 stderr默认值: \"\" 环境变量: INFLUXDB_HTTP_ACCESS_LOG_PATH access-log-status-filters访问日志根据状态码过滤，示例：[200, 5xx]默认值: [] 环境变量: INFLUXDB_HTTP_ACCESS_LOG_STATUS_FILTERS_0 INFLUXDB_HTTP_ACCESS_LOG_STATUS_FILTERS_1 write-tracing是否开启写入详细日志默认值: false 环境变量: INFLUXDB_HTTP_WRITE_TRACING pprof-enabled是否开启 pprof默认值: true 环境变量: INFLUXDB_HTTP_PPROF_ENABLED https-enabled是否开启 https默认值: false 环境变量: INFLUXDB_HTTP_HTTPS_ENABLED https-certificatehttps 证书默认值: \"/etc/ssl/influxdb.pem\" 环境变量: INFLUXDB_HTTP_HTTPS_CERTIFICATE https-private-keyhttps 私钥默认值: \"\" 环境变量: INFLUXDB_HTTP_HTTPS_PRIVATE_KEY shared-secret共享密钥，JWT 授权共享密钥用于使用 JSON Web 令牌 (JWT) 验证请求。默认值: \"\" 环境变量: INFLUXDB_HTTP_SHARED_SECRET max-body-size客户端请求正文的最大大小（以字节为单位）。当 HTTP 客户端发送的数据超过配置的最大大小时，将返回 413 Request Entity Too Large HTTP 响应。要禁用此限制，请将值设置为0。默认值: 25000000 环境变量: INFLUXDB_HTTP_MAX_BODY_SIZE max-row-limit查询返回的最大行数默认值: 0 环境变量: INFLUXDB_HTTP_MAX_ROW_LIMIT max-connection-limit最大连接数限制默认值: 0 环境变量: INFLUXDB_HTTP_MAX_CONNECTION_LIMIT unix-socket-enabled使用 UNIX domain socket 启用 http 服务默认值: false 环境变量: INFLUXDB_HTTP_UNIX_SOCKET_ENABLED bind-socketUNIX domain socket 路径默认值: \"/var/run/influxdb.sock\" 环境变量: INFLUXDB_HTTP_BIND_SOCKET max-concurrent-write-limit最大并发写入限制默认值: 0 环境变量: INFLUXDB_HTTP_MAX_CONCURRENT_WRITE_LIMIT max-enqueued-write-limit最大写入队列限制默认值: 0 环境变量: INFLUXDB_HTTP_MAX_ENQUEUED_WRITE_LIMIT enqueued-write-timeout写入等待超时限制默认值: 0 环境变量: INFLUXDB_HTTP_ENQUEUED_WRITE_TIMEOUT Logging 日志[logging]format确定用于日志的日志编码器。有效选项为 auto、logfmt 和 json。如果输出终端是 TTY，则设置为 auto 会使用更用户友好的输出格式，但该格式不易被机器读取。当输出终端为非 TTY 时，auto 将使用logfmt。默认值: \"logfmt\" 环境变量: INFLUXDB_LOGGING_FORMAT level日志等级默认值: \"info\" 环境变量: INFLUXDB_LOGGING_LEVEL suppress-logo关闭程序启动时的 logo 打印默认值: false 环境变量: INFLUXDB_LOGGING_SUPPRESS_LOGO Subscriber 订阅[subscriber] 控制订阅，可用于分叉 InfluxDB 主机接收的所有数据的副本。enabled是否启用默认值: true 环境变量: INFLUXDB_SUBSCRIBER_ENABLED http-timeouthttp 超时默认值: \"30s\" 环境变量: INFLUXDB_SUBSCRIBER_HTTP_TIMEOUT insecure-skip-verify允许不安全的 https 连接默认值: false 环境变量: INFLUXDB_SUBSCRIBER_INSECURE_SKIP_VERIFY ca-certsca 证书，不设置时使用系统默认证书默认值: \"\" 环境变量: INFLUXDB_SUBSCRIBER_CA_CERTS write-concurrency写并发默认值: 40 环境变量: INFLUXDB_SUBSCRIBER_WRITE_CONCURRENCY write-buffer-size写入缓冲区大小默认值: 1000 环境变量: INFLUXDB_SUBSCRIBER_WRITE_BUFFER_SIZE total-buffer-bytes总缓存字节数，所有订阅中分配给缓冲区的总字节数。每个命名订阅均会获得相等的份额默认值: 0 环境变量: INFLUXDB_SUBSCRIBER_TOTAL_BUFFER_BYTES Graphite Graphite协议[[graphite]] Graphite 监听器控制Collectd CollectD协议[[collectd]] Collectd 监听器控制OpenTSDB OpenTSDB协议[[openTSDB]] OpenTSDB 监听器控制UDP UDP协议[[udp]] UDP 监听器控制Continuous queries 连续查询[continuous_queries] 控制如何在 InfluxDB 中运行连续查询。enabled是否启用默认值: true 环境变量: INFLUXDB_CONTINUOUS_QUERIES_ENABLED log-enabled是否开启日志默认值: true 环境变量: INFLUXDB_CONTINUOUS_QUERIES_LOG_ENABLED query-stats-enabled是否开启查询统计默认值: false 环境变量: INFLUXDB_CONTINUOUS_QUERIES_QUERY_STATS_ENABLED run-interval默认值: \"1s\" 环境变量: INFLUXDB_CONTINUOUS_QUERIES_RUN_INTERVAL TLS TLS加密[tls] InfluxDB 中传输层安全性 (TLS) 的全局配置设置。如果未指定 TLS 配置设置，InfluxDB 将支持Gocrypto/tls包常量部分列出的所有密码套件 ID 以及实现的所有 TLS 版本，具体取决于用于构建 InfluxDB 的 Go 版本。使用SHOW DIAGNOSTICS命令查看用于构建 InfluxDB 的 Go 版本。推荐版本ciphers = [ \"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\", \"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305\", \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\", \"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\", \"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\", \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\" ] min-version = \"tls1.3\" max-version = \"tls1.3\" min-version最小版本，默认使用 go crypto/tls 包中的最小版本，本例中是 tls1.3默认值: \"tls1.3\" 环境变量: INFLUXDB_TLS_MIN_VERSION max-version最大版本，默认使用 go crypto/tls 包中的最大版本，本例中是 tls1.3默认值: \"tls1.3\" 环境变量: INFLUXDB_TLS_MAX_VERSION Flux Query controls Flux查询[flux-controller] 本节包含 Flux 查询管理的配置设置。query-concurrency查询并发数限制默认值: 0 query-initial-memory-bytes查询初始内存分配限制默认值: 0 query-max-memory-bytes查询最大内存总数限制默认值: 0 total-max-memory-bytes总最大内存数限制默认值: 0 query-queue-size查询队列大小限制默认值: 0 Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-06-26 "},"doc_influxdb/administration_configure_meta_nodes.html":{"url":"doc_influxdb/administration_configure_meta_nodes.html","title":"配置 Meta 节点","keywords":"","body":" 配置 Meta 节点 Global 全局配置 reporting-disabled bind-address hostname Enterprise license 企业许可证 license-key license-path Meta 节点 dir bind-address http-bind-address https-enabled https-certificate https-private-key https-insecure-tls data-use-tls data-insecure-tls gossip-frequency announcement-expiration retention-autocreate election-timeout heartbeat-timeout leader-lease-timeout commit-timeout consensus-timeout cluster-tracing logging-enabled pprof-enabled lease-duration auth-enabled ldap-allowed internal-shared-secret password-hash ensure-fips TLS TLS加密 配置 Meta 节点Meta 节点配置设置 Global options Enterprise license [enterprise] Meta node [meta] TLS [tls] Global 全局配置reporting-disabled每 24 小时会将使用情况数据报告至 usage.influxdata.com。报告数据包含随机 ID、操作系统、架构、版本、系列数量以及其他使用情况数据。用户数据库的数据不会传输。将此选项更改为 true 可禁用报告功能。默认值: false bind-addressRPC服务用于节点间通信和备份与恢复的TCP绑定地址。默认值: \":8088\" 环境变量: INFLUXDB_BIND_ADDRESS hostname主机名默认值: \"localhost\" 环境变量: INFLUXDB_HOSTNAME Enterprise license 企业许可证[enterprise]license-key在InfluxPortal上为您创建的许可证密钥。元节点通过端口 80 或 443 将许可证密钥传输至portal.influxdata.com，并接收一个临时的 JSON 许可证文件。服务器会在本地缓存该许可证文件。如果没有有效的许可证文件，数据进程将只能运行有限时间。如果您的服务器无法与https://portal.influxdata.com通信，则必须使用license-path设置离线授权。默认值: \"\" 环境变量: INFLUXDB_ENTERPRISE_LICENSE_KEY license-path您从 InfluxData 收到的永久 JSON 许可证文件的本地路径，适用于无法访问互联网的实例。如果没有有效的许可证文件，数据处理将只能运行有限的时间。如果需要许可证文件，请联系sales@influxdb.com 。许可证文件应保存在集群中的每台服务器上，包括元节点、数据节点和企业节点。该文件包含 JSON 格式的许可证，并且必须可供influxdb用户读取。集群中的每台服务器都会独立验证其许可证。默认值: \"\" 环境变量: INFLUXDB_ENTERPRISE_LICENSE_PATH Meta 节点[meta]dir存储路径默认值: \"/var/lib/influxdb/meta\" 环境变量: INFLUXDB_META_DIR bind-address监听地址默认值: \":8089\" 环境变量: INFLUXDB_META_BIND_ADDRESS http-bind-addresshttp 监听地址 监听地址默认值: \":8091\" 环境变量: INFLUXDB_META_HTTP_BIND_ADDRESS https-enabled是否启用 https默认值: false 环境变量: INFLUXDB_META_HTTPS_ENABLED https-certificatehttps 证书默认值: \"\" 环境变量: INFLUXDB_META_HTTPS_CERTIFICATE https-private-keyhttps 私钥默认值: \"\" 环境变量: INFLUXDB_META_HTTPS_PRIVATE_KEY https-insecure-tls元节点是否跳过通过 HTTPS 相互通信的证书验证。这在使用自签名证书进行测试时很有用。默认值: false 环境变量: INFLUXDB_META_HTTPS_INSECURE_TLS data-use-tls与 Data 节点通信是否使用 tls 加密默认值: false 环境变量: INFLUXDB_META_DATA_USE_TLS data-insecure-tls与 Data 节点通信是否允许不安全证书默认值: false 环境变量: INFLUXDB_META_DATA_INSECURE_TLS gossip-frequency广播频率默认值: \"5s\" announcement-expiration公告有效期默认值: \"30s\" retention-autocreate创建bucket时自动创建保留策略默认值: true election-timeout选举超时默认值: \"1s\" heartbeat-timeout心跳超时默认值: \"1s\" leader-lease-timeout领导者 lease 超时，领导者租约超时是指 Raft 领导者在未收到大多数节点的回复时，仍能保持领导者地位的时间。超时后，领导者将降级为跟随者状态。节点间延迟较高的集群可能需要增加此参数，以避免不必要的 Raft 选举。默认值: \"500ms\" 环境变量: INFLUXDB_META_LEADER_LEASE_TIMEOUT commit-timeout提交超时是指领导者向追随者发送包含领导者提交索引的消息之间的时间间隔。默认设置适用于大多数系统。默认值: \"50ms\" 环境变量: INFLUXDB_META_COMMIT_TIMEOUT consensus-timeout在获取最新的 Raft 快照之前等待达成共识的超时。默认值: \"30s\" 环境变量: INFLUXDB_META_CONSENSUS_TIMEOUT cluster-tracing集群详细日志默认值: false 环境变量: INFLUXDB_META_CLUSTER_TRACING logging-enabled是否打印日志默认值: true 环境变量: INFLUXDB_META_LOGGING_ENABLED pprof-enabled是否开启 pprof默认值: true 环境变量: INFLUXDB_META_PPROF_ENABLED lease-duration数据节点从元节点获取的租约的默认期限。租约在满足期限后自动到期。 租约可确保在给定时间内只有一个数据节点在运行某些任务。例如，连续查询 (CQ) 使用租约，这样所有数据节点就不会同时运行相同的 CQ。默认值: \"1m0s\" 环境变量: INFLUXDB_META_LEASE_DURATION auth-enabled是否开启认证默认值: false 环境变量: INFLUXDB_META_AUTH_ENABLED ldap-allowed是否开启 ldap 认证默认值: false 环境变量: INFLUXDB_META_SHARED_SECRET internal-shared-secret内部共享密钥默认值: \"\" 环境变量: INFLUXDB_META_INTERNAL_SHARED_SECRET password-hash密码哈希默认值: \"bcrypt\" 环境变量: INFLUXDB_META_PASSWORD_HASH ensure-fips启动时是否检查 Influx 数据平台是否符合 FIPS 安全标准默认值: false 环境变量: INFLUXDB_META_ENSURE_FIPS TLS TLS加密[tls] 参考 Data 节点的 TLS 设置Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-07-02 "},"doc_influxdb/practice.html":{"url":"doc_influxdb/practice.html","title":"实践","keywords":"","body":"实践Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-07-03 "},"doc_influxdb/practice_cluster.html":{"url":"doc_influxdb/practice_cluster.html","title":"集群版实践","keywords":"","body":" InfluxDB 集群版实践 快速开始 可视化控制台 配置修改 influxdb.conf 建议修改 完整配置 influxdb-meta.conf 建议修改 完整配置 重要功能/机制 基本架构 数据存储结构 缓存队列（hinted handoff） 反熵（anti-entropy）【暂不支持】 备份还原 集群管理 节点故障测试 节点故障期间 生产环境最佳实践 不同场景 2K 设备 （6K points/s） 2K 设备 ~ 100K 设备（6K points/s ~ 300K points/s） 100K 设备以上 其他注意点 参考资料 InfluxDB 集群版实践快速开始使用 Docker-Compose 快速部署 http://gitlab.shuyilink.com/embeded-software/linkiiot/-/blob/develop/tool/influx/build/docker-compose.yml 包含 Data 节点 3，Meta 节点 3 初始化集群 https://github.com/chengshiwen/influxdb-cluster/wiki https://developer.aliyun.com/article/1056240 将 Data 节点和 Meta 节点加入集群必须先加入 Meta 节点否则报错influxd-ctl add-meta influxdb-meta-0:8091 influxd-ctl add-meta influxdb-meta-1:8091 influxd-ctl add-meta influxdb-meta-2:8091 influxd-ctl add-data influxdb-data-0:8088 influxd-ctl add-data influxdb-data-1:8088 influxd-ctl add-data influxdb-data-2:8088 # influxd-ctl show Data Nodes ========== ID TCP Address Version 4 influxdb-data-0:8088 1.8.11-c1.2.0 5 influxdb-data-1:8088 1.8.11-c1.2.0 6 influxdb-data-2:8088 1.8.11-c1.2.0 Meta Nodes ========== ID TCP Address Version 1 influxdb-meta-0:8091 1.8.11-c1.2.0 2 influxdb-meta-1:8091 1.8.11-c1.2.0 3 influxdb-meta-2:8091 1.8.11-c1.2.0 可视化控制台influx 1.8 没有内置的 Console，推荐使用官方工具 chronografhttps://docs.influxdata.com/chronograf/v1/introduction/installation/ 每次运行程序的目录不要变，默认会在运行目录下创建数据库存储配置文件，否则需要重新配置 - backup # 定期备份的配置目录 - chronograf-v1.db # 配置 配置修改influxdb.conf建议修改关闭 influx 自动数据收集，避免开源版纠纷 1. reporting-disabled = true 开启 flux 查询，为了能直接兼容现有 IoT 功能 1. [http] flux-enabled = true 开启认证提高安全性 1. [http] auth-enabled = true 设置 hinted-handoff 大小为 50GB，考虑 IoT 生产环境的需求，适当增大 1. [hinted-handoff] max-size = 53687091200 设置查询超时，防止 InfluxDB 被查爆，并开启慢查询日志 1. query-timeout = \"5m\" 2. log-queries-after = \"1m\" 3. log-timedout-queries = true 完整配置bind-address = \":8088\" reporting-disabled = true [http] flux-enabled = true auth-enabled = true [coordinator] query-timeout = \"5m\" log-queries-after = \"1m\" log-timedout-queries = true [meta] dir = \"/var/lib/influxdb/meta\" [hinted-handoff] dir = \"/var/lib/influxdb/hh\" max-size = 53687091200 [data] dir = \"/var/lib/influxdb/data\" wal-dir = \"/var/lib/influxdb/wal\" influxdb-meta.conf建议修改关闭 influx 自动数据收集，避免开源版纠纷 reporting-disabled = true 完整配置bind-address = \":8091\" reporting-disabled = true [meta] dir = \"/var/lib/influxdb/meta\" 重要功能/机制基本架构┌─────────────────────────────────────────────────────┐ │ Meta Nodes │ │ │ │ Meta1 Meta2 Meta3 │ └─────────────────────────────────────────────────────┘ ▲ | ▼ ┌─────────────────────────────────────────────────────┐ │ Data Nodes │ │ │ │ Data1 Data2 Data3 │ └─────────────────────────────────────────────────────┘ 数据存储结构 ┌──────────────── ─┐ │ Retention Policy │ └──────────────────┘ | +----------+---------+ | | ┌──────────────── ─┐ ┌──────────────── ─┐ │ Shard Group 1 │ │ Shard Group 2 │ └──────────────────┘ └──────────────────┘ | +---+----------+--------------+ | | | ┌───────────┐ ┌───────────┐ ┌───────────┐ │ Shard 1 │ │ Shard 2 │ │ Shard 3 │ └───────────┘ └───────────┘ └───────────┘ | +------------------+ | | ┌───────────────┐ ┌───────────────┐ ┌───────────────┐ │ Data Node 1 │ │ Data Node 2 │ │ Data Node 3 │ └───────────────┘ └───────────────┘ └───────────────┘ 保留策略、分片组、分片、复制因子、Data 节点 可以用过 influx 客户端工具查看 show shard groups，show shards 缓存队列（hinted handoff）默认7d，10G 需要预留资源给缓存队列恢复数据使用 反熵（anti-entropy）【暂不支持】节点宕机恢复后，自动同步数据分片 备份还原暂不支持备份/还原，仅支持导入/导出，可以自己做冷备集群管理当前支持 13 个集群管理功能，剩余 7 个功能尚未支持add-data：添加 Data 节点到集群 add-meta：添加 Meta 节点到集群 join：当前节点加入集群 leave：当前节点离开集群 update-data：更新 Data 节点（节点永久故障时替换） remove-data：删除 Data 节点（会永久删除数据） remove-meta：删除 Meta 节点（会永久删除节点） show：显示集群中的所有元和 Data 节点 show-shards：显示所有数据分片 token：生成一个访问 jwt token copy-shard：拷贝一个 Data 节点的数据分片到另一个 Data 节点（用于重新平衡集群） remove-shard：删除一个数据分片（用于重新平衡集群） truncate-shards：阶段热分片（用于重新平衡集群） 节点故障测试场景：3节点故障1个，缓存队列测试 测试条件：5000设备*100点/s节点故障期间节点1：9core 3G + 18G(SHR) 40分钟后hh目录到达11G，停止增长，此时节点2的hh目录大小4G 节点2：9core 3G + 18G(SHR) 50分钟后hh目录到达11G，停止增长 # 会有下列告警日志 ts=2025-06-19T02:37:08.436105Z lvl=warn msg=\"Write failed\" log_id=0xAuTToW000 service=write node_id=6 shard_id=2 error=\"hinted handoff queue not empty\" ts=2025-06-19T02:37:35.392779Z lvl=warn msg=\"Write failed\" log_id=0xAuTToW000 service=write node_id=6 shard_id=2 error=\"queue is full\" ts=2025-06-19T02:37:35.398806Z lvl=warn msg=\"Write shard failed with hinted handoff\" log_id=0xAuTToW000 service=write node_id=6 shard_id=2 error=\"queue is full\" 生产环境最佳实践只考虑变化上报，假定上报速率：1条/10s * 30点位需要提前确定好 Data 节点数量，否则后期扩容费时费力 Data 节点数 ≥ 3，复制因子 3，缓存队列 50 G 磁盘做冗余，至少 raid5。因为 influx 为了写入性能，默认配置中写入一致性是 one，即允许 2 节点故障。 资源要给够，每个节点需要按照正常写入时 2~3 倍分配 CPU 和 内存 1. 数据压缩需要额外资源：资源不足会导致数据压缩来不及，运行一段时间后缓存队列满了就无法写入了 2. 故障恢复需要额外资源：如果一个节点故障下线恢复后，恢复过程会资源占用*2~3，否则会影响恢复，导致该节点可能永远追不上其他两个节点 尽量在最大允许故障时间内恢复节点。 1. 如果1节点故障恢复超期可以不管，数据还有2副本 2. 如果2节点故障恢复，需要视情况而定 1. 极少的故障且较快恢复时，不处理。（如1年内就坏了1次，节点故障恢复用了2周） 2. 频繁的故障和较久的故障恢复时，需要人工介入平衡集群。 不同场景2K 设备 （6K points/s）3 副本数据都不丢失，单节点最大允许故障时间：7.5 天。 2K 设备 ~ 100K 设备（6K points/s ~ 300K points/s）按需部署 InfluxDB Data 节点（每个节点实际设备数 ≈ 设备数*复制因子/节点数） 1. 如果资源充足，按照 2K 设备 1个 Data 节点估算，单节点最大允许故障时间：7.5 天 2. 如果资源不足，按照 10K 设备 1个 Data 节点估算，单节点最大允许故障时间：1.5 天 节点故障时间超期 1. 功能上无影响：数据写入、查询、故障恢复都没有问题，influx 只要有 1 个节点有数据就能查到 2. 如果故障 1 个节点超期：一般不处理，数据仍有 2 副本 3. 如果故障 2 个节点超期：故障次数少，时间短时一般不处理。要求做磁盘冗余，即使1副本数据也不会丢失 4. 若长期&频繁的节点故障，集群状态会变得不健康，这会导致集群数据分布不均匀，此时需要人工介入重新平衡集群 缓存队列大小估计公式：点位速率（points/s） 时间（h） 4e-05 1. 示例：100000 1 4e-05 = 4，表示 100K points/s 的写入持续 1 小时，缓存队列长度会变成 4 GB。 故障节点恢复后在 300K/s 的写入压力下缓存队列的数据能够以 4G/h 的速度恢复，写入压力降低恢复速度会变快 在 500K/s 的写入压力下缓存队列只增不减 100K 设备以上使用更多的 Data 节点 需要使用 influx-proxy 一致性哈希算法水平扩展 ┌──────────────────┐ │ writes & queries │ └──────────────────┘ │ ▼ ┌──────────────────┐ │ │ │ InfluxDB Proxy │ │ (only http) │ │ │ └──────────────────┘ │ ▼ ┌──────────────────┐ │ db,measurement │ │ consistent hash │ └──────────────────┘ | | ┌─┼──────────────┘ │ └────────────────┐ ▼ ▼ Circle 1 Circle 2 ┌────────────┐ ┌────────────┐ │ │ │ │ │ InfluxDB 1 │ │ InfluxDB 3 │ │ InfluxDB 2 │ │ InfluxDB 4 │ │ │ │ │ └────────────┘ └────────────┘ 其他注意点性能错觉：可能写入来得及，但其实集群不健康 1. 数据压缩来不及（后台异步压缩线程，一个单次压缩任务可能就需要几十分钟），导致长时间运行后待压缩数据过多拒绝写入。 2. 缓存队列逐渐变长（只有1副本正常写入，但该节点的缓存队列同步不及，会逐渐变成直至集群不健康） 部署时需要修改实例保活策略，当一个节点长期下线恢复后，它会先追数据，这个时候不会启动http服务，默认的健康检测会导致被k8s干掉，影响数据恢复 influx 不要存太多数据，最佳实践是冷热数据分离，influx 只存少量热数据，通过导出冷备到对象存储 当前版本 v1.8.11-c1.2.0 不支持反熵相关功能，还在项目开发计划中。所以扩容集群需要手动处理：https://docs.influxdata.com/enterprise_influxdb/v1/administration/manage/clusters/rebalance/ 参考资料https://docs.influxdata.com/enterprise_influxdb/v1/ https://github.com/chengshiwen/influxdb-cluster/wiki#%E7%AE%A1%E7%90%86%E6%8C%87%E5%8D%97 https://github.com/chengshiwen/influx-proxy Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-07-03 "},"doc_golang/":{"url":"doc_golang/","title":"Golang","keywords":"","body":"简介Golang 学习笔记Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-07-09 "},"doc_golang/cobra.html":{"url":"doc_golang/cobra.html","title":"cobra","keywords":"","body":" Cobra 示例 Cobracobra 是一个广受好评的创建命令行客户端的库：https://github.com/spf13/cobra示例var rootCmd = &cobra.Command{ Use: \"cmd\", Short: \"命令行辅助工具\", } var grafanaCmd = &cobra.Command{ Use: \"grafana\", Short: \"grafana辅助功能\", } var reloadCfgCmd = &cobra.Command{ Use: \"reloadcfg\", Short: \"重新载入配置\", Run: func(cmd *cobra.Command, args []string) { // do something ... }, } func init() { // 需要预先注册，支持多级命令 grafanaCmd.AddCommand(reloadCfgCmd) rootCmd.AddCommand(grafanaCmd) } func main() { err := rootCmd.Execute() if err != nil { os.Exit(1) } } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-08-27 "},"doc_golang/channel.html":{"url":"doc_golang/channel.html","title":"channel","keywords":"","body":" channel 代码解读 go 版本: 1.22.2 关键结构 代码解读 chansend() chanrecv() closechan() channel 代码解读go 版本: 1.22.2关键结构type hchan struct { qcount uint // 当前队列中剩余的元素个数 dataqsiz uint // 环形队列的长度，即可以存放的元素个数 buf unsafe.Pointer // 环形队列的指针 elemsize uint16 // 每个元素的大小 closed uint32 // 标识channel是否已关闭 elemtype *_type // 元素类型 sendx uint // 队列下标，指示生产者写入时存到哪里 recvx uint // 队列下标，指示消费者从哪里取 recvq waitq // 等待读消息的Goroutine队列（sudog的链表） sendq waitq // 等待写消息的Goroutine队列（sudog的链表） lock mutex // lock保护hchan中的所有字段，以及在此channel上阻塞的sudogs中的多个字段 } // waitq 是一个 sudog 的双向链表，sudog 是对 G 的封装，包含了 Goroutine 和要发送/接收的数据的指针等信息。 type waitq struct { first *sudog last *sudog } 代码解读chansend()发送数据，ch func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { // ... // 1.先获取锁 lock(&c.lock) // 2.如果 channel 已关闭，则 panic if c.closed != 0 { unlock(&c.lock) panic(plainError(\"send on closed channel\")) } // 3.寻找等待的接收者！最高优先级！ // 如果有一个Goroutine在recvq中等待，说明缓冲区是空的，或者根本没有缓冲区。 // 此时我们直接“绕过缓冲区”，将数据直接拷贝给这个接收者，并唤醒它。 if sg := c.recvq.dequeue(); sg != nil { send(c, sg, ep, func() { unlock(&c.lock) }, 3) return true } // 4.如果缓冲区还有空间，则将数据拷贝到缓冲区中，更新索引。 if c.qcount 锁：获取 hchan 的锁。 非阻塞检查：如果是非阻塞模式且无法立即发送，直接返回 false。 直接投递（最高效）：如果发现有接收者正在等待（recvq 不为空），则跳过缓冲区，直接将数据从发送者拷贝到接收者，并唤醒接收者 Goroutine。这避免了一次额外的内存拷贝（从发送者->缓冲区->接收者）。 缓冲投递：如果缓冲区未满，则将数据拷贝到缓冲区的 sendx 位置，更新索引。 阻塞等待：如果前两步都不成立（即没有等待的接收者且缓冲区已满），则将当前 Goroutine 包装成 sudog 加入 sendq，并调用 gopark 将其挂起。当有接收者到来或 Channel 被关闭时，它会被唤醒。 chanrecv()接收数据，x func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { // ... lock(&c.lock) // 1.快速路径：非阻塞且无法立即接收 if !block && (c.qcount == 0 && c.sendq.first == nil || c.closed != 0) { // ... return false, false } // 2.Channel已关闭且缓冲区无数据，返回零值 if c.closed != 0 && c.qcount == 0 { // ... return true, false } // 3.寻找等待的发送者！最高优先级！ // 如果有一个Goroutine在sendq中等待，说明缓冲区是满的，或者根本没有缓冲区。 // a. 对于无缓冲Channel：直接从发送者拷贝数据。 // b. 对于有缓冲Channel：将缓冲区recvx位置的数据拷贝给接收者，再将发送者的数据拷贝到缓冲区中，然后更新环形队列索引 if sg := c.sendq.dequeue(); sg != nil { recv(c, sg, ep, func() { unlock(&c.lock) }, 3) return true, true } // 4.如果缓冲区有数据，则从缓冲区拷贝数据。 if c.qcount > 0 { qp := chanbuf(c, c.recvx) if ep != nil { typedmemmove(c.elemtype, ep, qp) // 从缓冲区拷贝到接收变量 } // ... 清空缓冲区该位置的数据（根据类型是否需要内存清理） c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.qcount-- unlock(&c.lock) return true, true } // 5.阻塞路径：缓冲区空且无等待的发送者。 // 将当前Goroutine打包成sudog，放入recvq队列，并挂起。 if !block { unlock(&c.lock) return false, false } gp := getg() mysg := acquireSudog() // ... c.recvq.enqueue(mysg) gp.parkingOnChan.Store(true) gopark(chanparkcommit, unsafe.Pointer(&c.lock), waitReasonChanReceive, traceBlockChanReceive, 2) // 挂起 // 被唤醒后... // ... return true, !closed } 直接接收：如果发现有发送者正在等待（sendq 不为空），则调用 recv 函数。这里有两种情况：无缓冲 Channel：直接从发送者拷贝数据到接收者。 有缓冲 Channel：这是一个优化点。它先将缓冲区头部的元素（recvx 位置）拷贝给接收者，然后再将阻塞的发送者的数据直接拷贝到缓冲区刚刚空出来的位置，并更新索引。这避免了唤醒发送者后，发送者再去写缓冲区的一次额外拷贝和锁竞争。 缓冲接收：如果缓冲区有数据，则从缓冲区拷贝数据。 阻塞等待：如果没有数据，则将当前 Goroutine 加入 recvq 并挂起。 closechan()关闭 channel，close(ch)func closechan(c *hchan) { // 1.检查合法性（不能close一个nil channel） if c == nil { panic(plainError(\"close of nil channel\")) } lock(&c.lock) // 2.检查是否已关闭（不能重复close） if c.closed != 0 { unlock(&c.lock) panic(plainError(\"close of closed channel\")) } // 3.设置关闭标志 c.closed = 1 // 4.唤醒所有等待的接收者（recvq） // 接收者会被唤醒，并获取到零值。 var glist gList for { sg := c.recvq.dequeue() if sg == nil { break } // ... 将sg关联的G加入到glist } // 5.唤醒所有等待的发送者（sendq） // 发送者会被唤醒，然后panic（因为不能向已关闭的channel发送数据）。 for { sg := c.sendq.dequeue() if sg == nil { break } // ... 将sg关联的G加入到glist } unlock(&c.lock) // 6.在锁外唤醒所有被阻塞的Goroutine for !glist.empty() { gp := glist.pop() gp.schedlink = 0 goready(gp, 3) // 将G的状态从_Gwaiting改为_Grunnable，放入运行队列 } } 设置 closed 标志。 释放所有的接收者（recvq），它们会收到该类型的零值，并且 received 返回 false。 释放所有的发送者（sendq），它们会触发 panic（因为试图向已关闭的 Channel 发送数据）。 Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-09-01 "},"doc_golang/pprof.html":{"url":"doc_golang/pprof.html","title":"pprof 调试","keywords":"","body":" pprof 调试 1.启用 pprof 2.安装依赖 3.查看分析 离线模式 在线模式 pprof 调试1.启用 pprofimport ( \"net/http\" _ \"net/http/pprof\" ) go func() { http.ListenAndServe(\":8102\", nil) }() 2.安装依赖配置后可以更方便的在浏览器中查看图表1.需要 graphviz 依赖，wsl + ubuntu 方式示例：sudo apt install graphviz 2.需要指定浏览器，wsl + ubuntu + chrome 方式示例：sudo ln -s /mnt/c/Program\\ Files/Google/Chrome/Application/chrome.exe /usr/bin/mschrome sudo update-alternatives --install /usr/bin/x-www-browser x-www-browser /usr/bin/mschrome 200 3.需要设置环境变量：export BROWSER=/usr/bin/mschrome 3.查看分析离线模式curl -o profile http://localhost:8888/debug/pprof/profile go tool pprof -http=:8080 profile.data go tool pprof -http=:8889 heap.data go tool trace trace.data 在线模式go tool pprof -http=:8000 http://192.168.129.130:8888/debug/pprof/heap Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-07-09 "},"doc_golang/slice.html":{"url":"doc_golang/slice.html","title":"slice","keywords":"","body":" slice 代码解读 go 版本: 1.22.2 关键结构 代码解读 makeslice growslice slice 代码解读go 版本: 1.22.2关键结构// path: src/runtime/slice.go type slice struct { array unsafe.Pointer // 指向底层数组的指针 len int // 当前切片的长度（当前使用的元素个数） cap int // 当前切片的容量（底层数组的总长度） } 当你编写 s := make([]int, 5, 10) 时，在内存中会创建这样一个结构： s (slice header) +--------+--------+--------+ | array | len=5 | cap=10 | +--------+--------+--------+ | | (底层数组) v +----+----+----+----+----+----+----+----+----+----+ | | | | | | | | | | | [10]int +----+----+----+----+----+----+----+----+----+----+ ^ ^ ^ | | | s[0] s[4] s[:9] 的终点 代码解读makeslicemake([]T, len, cap) 会调用 runtime.makeslice// path: src/runtime/slice.go func makeslice(et *_type, len, cap int) unsafe.Pointer { // 计算需要分配的总内存大小 = 容量 * 元素大小 mem, overflow := math.MulUintptr(et.Size_, uintptr(cap)) if overflow || mem > maxAlloc || len cap { // 安全检查： // 1. 内存计算是否溢出 // 2. 申请的内存是否超过系统限制 // 3. 长度是否小于0 // 4. 长度是否大于容量 mem, overflow := math.MulUintptr(et.Size_, uintptr(len)) if overflow || mem > maxAlloc || len growsliceappend 容量不足时会调用 runtime.growslice// path: src/runtime/slice.go // old = 旧slice, cap = 所需的最小容量（通常是 old.cap + 新增元素个数） func growslice(et *_type, old slice, cap int) slice { // ... (省略一些边界检查和特殊情况处理) // 核心策略：计算新的容量 newcap := old.cap doublecap := newcap + newcap if cap > doublecap { // 情况1：如果所需容量超过旧容量的2倍，则直接使用所需容量。 newcap = cap } else { const threshold = 256 if old.cap = 256，采用一种平滑的增长因子，避免内存浪费。 // 循环每次增加 (newcap + 3*threshold) / 4，直到 newcap >= cap for 0 Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-09-02 "},"doc_golang/map.html":{"url":"doc_golang/map.html","title":"sync.map","keywords":"","body":" sync.Mutex 代码解读 go 版本: 1.22.2 设计思想 关键结构 代码解读 sync.Mutex 代码解读go 版本: 1.22.2设计思想sync.map 底层其实是两个 map，一个 read map，一个 dirty map，read map 并发读安全，所有读操作优先read map，所有写直接操作 dirty map，read map 和 dirty map 在需要时间会进行数据同步 标记删除，如果 dirty map 提升成 read map 后没有新元素写入，则删除只是增加标记，然后直到 dirty map 提升时删除，关注 missLocked 和 dirtyLocked 函数 关键结构type Map struct { mu Mutex // read map，读并发安全，更新时需要对 mu 加锁 read atomic.Pointer[readOnly] // dirty map dirty map[any]*entry // read map 最后一次更新后，load 缓存失效次数，次数够多时将 dirty map 提升为 read map misses int } // readOnly 是存在 Map.read 中永远不会被修改的结构 type readOnly struct { m map[any]*entry amended bool // 如果 dirty map 包含 read map 中不存在的元素则为 true } // expunged 是一个固定的标记，表示一个元素已经被逻辑删除 var expunged = new(any) // entry 条目是映射中与特定键相对应的槽 type entry struct { // p 是指向一个值的指针 // // 如果 p == nil, 则 entry 已经被删除，此时 m.dirty == nil 或者 m.dirty[key] 是 entry // 如果 p == expunged, 则 entry 已经被删除, 此时 m.dirty != nil, 且 m.dirty 不存在 entry // 否则, entry 有效，存在于 m.read.m[key] 并且如果 m.dirty != nil 则同时存在于 m.dirty[key] p atomic.Pointer[any] } 代码解读// newEntry 初始化新的 entry func newEntry(i any) *entry { e := &entry{} e.p.Store(&i) return e } // 加载 read map func (m *Map) loadReadOnly() readOnly { if p := m.read.Load(); p != nil { return *p } return readOnly{} } // 加载一个元素 func (m *Map) Load(key any) (value any, ok bool) { read := m.loadReadOnly() e, ok := read.m[key] if !ok && read.amended { m.mu.Lock() // 加锁 && double check read = m.loadReadOnly() e, ok = read.m[key] if !ok && read.amended { e, ok = m.dirty[key] // 增加 miss 计数，如果过大则将 dirty map 提升成 read map m.missLocked() } m.mu.Unlock() } if !ok { return nil, false } return e.load() } // load 加载 entry 中的元素，如果 p == nil 或 p == expunged 都表示元素已删除 func (e *entry) load() (value any, ok bool) { p := e.p.Load() if p == nil || p == expunged { return nil, false } return *p, true } // Store 存储一个元素 func (m *Map) Store(key, value any) { _, _ = m.Swap(key, value) } // tryCompareAndSwap 尝试替换一个值 func (e *entry) tryCompareAndSwap(old, new any) bool { p := e.p.Load() // 元素被删或者旧值变更就直接失败 if p == nil || p == expunged || *p != old { return false } nc := new for { // 如果刚好被并发更新了值就重试直到成功 if e.p.CompareAndSwap(p, &nc) { return true } p = e.p.Load() if p == nil || p == expunged || *p != old { return false } } } // unexpungeLocked 删除 expunged 标记 func (e *entry) unexpungeLocked() (wasExpunged bool) { return e.p.CompareAndSwap(expunged, nil) } // swapLocked 原子性的替换指针 func (e *entry) swapLocked(i *any) *any { return e.p.Swap(i) } // LoadOrStore func (m *Map) LoadOrStore(key, value any) (actual any, loaded bool) { // 快速路径，无锁查询 read map read := m.loadReadOnly() if e, ok := read.m[key]; ok { actual, loaded, ok := e.tryLoadOrStore(value) if ok { return actual, loaded } } m.mu.Lock() read = m.loadReadOnly() if e, ok := read.m[key]; ok { if e.unexpungeLocked() { m.dirty[key] = e } actual, loaded, _ = e.tryLoadOrStore(value) } else if e, ok := m.dirty[key]; ok { actual, loaded, _ = e.tryLoadOrStore(value) m.missLocked() } else { if !read.amended { m.dirtyLocked() m.read.Store(&readOnly{m: read.m, amended: true}) } m.dirty[key] = newEntry(value) actual, loaded = value, false } m.mu.Unlock() return actual, loaded } // tryLoadOrStore func (e *entry) tryLoadOrStore(i any) (actual any, loaded, ok bool) { // 无锁快速判断 p := e.p.Load() if p == expunged { return nil, false, false } if p != nil { return *p, true, true } ic := i for { if e.p.CompareAndSwap(nil, &ic) { return i, false, true } p = e.p.Load() if p == expunged { return nil, false, false } if p != nil { return *p, true, true } } } // LoadAndDelete func (m *Map) LoadAndDelete(key any) (value any, loaded bool) { read := m.loadReadOnly() e, ok := read.m[key] if !ok && read.amended { m.mu.Lock() read = m.loadReadOnly() e, ok = read.m[key] if !ok && read.amended { e, ok = m.dirty[key] // 从 dirty map 实际删除 delete(m.dirty, key) m.missLocked() } m.mu.Unlock() } if ok { // 逻辑删除 return e.delete() } return nil, false } // delete 标记元素逻辑删除 func (e *entry) delete() (value any, ok bool) { for { p := e.p.Load() if p == nil || p == expunged { return nil, false } if e.p.CompareAndSwap(p, nil) { return *p, true } } } // trySwap 快速路径尝试交换 func (e *entry) trySwap(i *any) (*any, bool) { for { p := e.p.Load() if p == expunged { return nil, false } if e.p.CompareAndSwap(p, i) { return p, true } } } func (m *Map) Swap(key, value any) (previous any, loaded bool) { read := m.loadReadOnly() if e, ok := read.m[key]; ok { if v, ok := e.trySwap(&value); ok { if v == nil { return nil, false } return *v, true } } m.mu.Lock() read = m.loadReadOnly() // 先从 read map 尝试读一次 if e, ok := read.m[key]; ok { if e.unexpungeLocked() { // 如果原先有 expunged 标记，则表示 dirty map 非空，并需要更新该值到 dirty map m.dirty[key] = e } if v := e.swapLocked(&value); v != nil { // 返回旧值 loaded = true previous = *v } } else if e, ok := m.dirty[key]; ok { // 从 dirty map 查询 if v := e.swapLocked(&value); v != nil { loaded = true previous = *v } } else { if !read.amended { // 如果是插入第一个值到 dirty map，需要标记 read map 不完整 m.dirtyLocked() m.read.Store(&readOnly{m: read.m, amended: true}) } // 直接往 dirty map 插入新值 m.dirty[key] = newEntry(value) } m.mu.Unlock() return previous, loaded } // CompareAndSwap func (m *Map) CompareAndSwap(key, old, new any) bool { read := m.loadReadOnly() if e, ok := read.m[key]; ok { return e.tryCompareAndSwap(old, new) } else if !read.amended { return false // No existing value for key. } m.mu.Lock() defer m.mu.Unlock() read = m.loadReadOnly() swapped := false if e, ok := read.m[key]; ok { swapped = e.tryCompareAndSwap(old, new) } else if e, ok := m.dirty[key]; ok { swapped = e.tryCompareAndSwap(old, new) m.missLocked() } return swapped } // CompareAndDelete func (m *Map) CompareAndDelete(key, old any) (deleted bool) { read := m.loadReadOnly() e, ok := read.m[key] if !ok && read.amended { m.mu.Lock() read = m.loadReadOnly() e, ok = read.m[key] if !ok && read.amended { e, ok = m.dirty[key] m.missLocked() } m.mu.Unlock() } for ok { p := e.p.Load() if p == nil || p == expunged || *p != old { return false } if e.p.CompareAndSwap(p, nil) { return true } } return false } // Range 遍历元素 func (m *Map) Range(f func(key, value any) bool) { read := m.loadReadOnly() if read.amended { m.mu.Lock() read = m.loadReadOnly() if read.amended { // 提升 dirty map 成 read map read = readOnly{m: m.dirty} copyRead := read m.read.Store(&copyRead) m.dirty = nil m.misses = 0 } m.mu.Unlock() } for k, e := range read.m { v, ok := e.load() if !ok { continue } if !f(k, v) { break } } } // missLocked 增加 miss 计数，如果过大则将 dirty map 提升成 read map func (m *Map) missLocked() { m.misses++ if m.misses Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-08-26 "},"doc_golang/mutex.html":{"url":"doc_golang/mutex.html","title":"sync.Mutex","keywords":"","body":" sync.Mutex 代码解读 go 版本: 1.22.2 设计思想 关键结构 state 结构 mutexStarving 表示的两种模式 代码解读 Lock() Unlock() TryLock() sync.Mutex 代码解读go 版本: 1.22.2设计思想原子操作与状态压缩：使用一个 state 变量和位操作来管理所有状态，极大减少了需要同步的内存空间，提高了缓存友好性。 混合策略：结合了乐观的自旋（避免上下文切换开销）和悲观的排队（保证最终能获取到锁）。 自适应公平性：通过正常模式和饥饿模式的切换，在高吞吐量和公平性之间做出了优秀的权衡。正常情况下偏向吞吐量，一旦发现有 goroutine 等待过久，就切换到公平的饥饿模式，防止饿死。 信号量：底层依赖 sema（信号量）和运行时调度器 (runtime_SemacquireMutex / runtime_Semrelease) 来实现 goroutine 的阻塞和唤醒。 关键结构type Mutex struct { state int32 // 状态位 sema uint32 // 信号量地址 } type Locker interface { Lock() Unlock() } state 结构| 31.............................. 3 | 2 | 1 | 0 | | | mutexStarving | mutexWoken | mutexLocked | | 等待的 goroutine 数量 | 是否饥饿模式 | 有协程被唤醒 | 是否被锁定 | 第 0 位 (最低位): mutexLocked。为 1 表示锁已被某个 goroutine 持有。 第 1 位: mutexWoken。为 1 表示已经有 goroutine 被唤醒，正在尝试获取锁。这告诉 Unlock 方法不需要再去唤醒其他等待者，因为已经有一个活跃的 goroutine 了。 第 2 位: mutexStarving。为 1 表示当前锁处于饥饿模式。 第 3 位到第 31 位: 表示当前在等待这个锁的 goroutine 的数量。数量值等于 state >> mutexWaiterShift。 mutexStarving 表示的两种模式正常模式：等待的 goroutine 会先进行自旋尝试获取锁，若自旋多次后仍未获取到，则进入一个 FIFO 队列等待。新来的 goroutine 有优势，可能会比早已等待的 goroutine 先拿到锁（这提供了更高的吞吐量，但可能导致等待时间过长）。 饥饿模式：当一个等待的 goroutine 超过 starvationThresholdNs (1ms) 还没获取到锁时，锁会转变为饥饿模式。在饥饿模式下，锁的所有权会从执行 Unlock 的 goroutine 直接移交给队列最前端的等待者。新来的 goroutine 不会尝试获取锁，也不会自旋，而是直接加入到队列的末尾。这防止了尾部延迟现象，保证了公平性。 代码解读Lock()Lock()func (m *Mutex) Lock() { // 尝试快速路径(Fast Path)加锁，更新 state: [0|0|0|0] -> [0|0|0|1] if atomic.CompareAndSwapInt32(&m.state, 0, mutexLocked) { // 成功：加锁成功，函数返回 return } // 进入慢速路径(Slow Path)加锁 m.lockSlow() } lockSlow()func (m *Mutex) lockSlow() { // 初始化状态，然后通过自旋或者信号量排队获取锁 var waitStartTime int64 // 当前锁等待时长 starving := false // 当前协程是否饥饿 awoke := false // 当前协程是否唤醒 iter := 0 // 迭代次数，用于判断是否能自旋 old := m.state // 记录当前状态 for { // 如果当前是状态是 [*|0|*|1](正常模式&锁定) && 运行环境允许自旋：使用自旋等待锁 if old&(mutexLocked|mutexStarving) == mutexLocked && runtime_canSpin(iter) { // 如果当前协程未唤醒 && 当前状态未唤醒 && 有协程等待唤醒 [n|*|0|*] && if !awoke && old&mutexWoken == 0 && old>>mutexWaiterShift != 0 && // 更新状态为有协程被唤醒 // [n|0|0|1] -> [n|0|1|1] atomic.CompareAndSwapInt32(&m.state, old, old|mutexWoken) { // 标记当前协程被唤醒 awoke = true } // 自旋等待后再次尝试获取锁 runtime_doSpin() iter++ old = m.state continue } new := old // 如果是正常模式，更新为：已锁定。不要获取饥饿模式的互斥量，新到达的协程必须排队 // [*|0|*|*] -> [*|0|*|1] if old&mutexStarving == 0 { new |= mutexLocked } // 如果已锁定 || 处于饥饿模式：增加协程等待唤醒数 // [n|*|*|1] -> [n+1|*|*|1] // [n|1|*|*] -> [n+1|1|*|*] if old&(mutexLocked|mutexStarving) != 0 { new += 1 [*|1|*|1] if starving && old&mutexLocked != 0 { new |= mutexStarving } if awoke { // 状态一致性断言 if new&mutexWoken == 0 { throw(\"sync: inconsistent mutex state\") } // 当前协程唤醒结束，清除标记位 // [*|*|1|*] -> [*|*|0|*] new &^= mutexWoken } if atomic.CompareAndSwapInt32(&m.state, old, new) { // 旧状态是 [*|0|*|0] 的互斥量加锁成功就返回 if old&(mutexLocked|mutexStarving) == 0 { break } // 新来的协程：FIFO，插到队尾等待 // 已经等待过的协程：LIFO，插到队首立即执行，利用CPU缓存局部性优化性能 queueLifo := waitStartTime != 0 if waitStartTime == 0 { waitStartTime = runtime_nanotime() } // 挂起当前协程，等待调度 runtime_SemacquireMutex(&m.sema, queueLifo, 1) // 等待时间超过阈值 starvationThresholdNs 则更新为饥饿状态 starving = starving || runtime_nanotime()-waitStartTime > starvationThresholdNs old = m.state // 如果当前状态处于饥饿模式：[*|1|*|*|] if old&mutexStarving != 0 { // 如果当前协程被唤醒并且处于饥饿模式，检查状态一致性，不应该出现下列状态： // [*|*|*|1] || [0|*|*|*] // [*|*|1|*] || [0|*|*|*] if old&(mutexLocked|mutexWoken) != 0 || old>>mutexWaiterShift == 0 { throw(\"sync: inconsistent mutex state\") } delta := int32(mutexLocked - 1>mutexWaiterShift == 1 { // 如果非饥饿处理，或者处理完最后一个等待者时， // 就离开结束饥饿模式，防止2个协程无限礼让，一直维持饥饿模式降低性能 // [n|1|0|0] -> [n-1|0|0|1] delta -= mutexStarving } // [n|1|0|0] -> [n-1|1|0|1] atomic.AddInt32(&m.state, delta) break } awoke = true iter = 0 } else { old = m.state } } } Unlock()Unlock()func (m *Mutex) Unlock() { // 尝试快速路径(Fast Path)解锁 new := atomic.AddInt32(&m.state, -mutexLocked) if new != 0 { // 慢速路径解锁(Slow Path) m.unlockSlow(new) } } unlockSlow()func (m *Mutex) unlockSlow(new int32) { // new为-1时报错重复解锁 if (new+mutexLocked)&mutexLocked == 0 { fatal(\"sync: unlock of unlocked mutex\") } if new&mutexStarving == 0 { // 正常模式 old := new for { // 无需唤醒：如果没有等待者或者已有协程拿到了该锁，则直接退出 // [0|*|*|*] || [*|1|*|*] // [0|*|*|*] || [*|*|1|*] // [0|*|*|*] || [*|*|*|1] if old>>mutexWaiterShift == 0 || old&(mutexLocked|mutexWoken|mutexStarving) != 0 { return } // 唤醒成功：通过信号量唤醒一个协程 // [n|0|0|0] -> [n-1|0|1|0] new = (old - 1 TryLock()func (m *Mutex) TryLock() bool { old := m.state // 已经锁定或处于饥饿模式时直接失败 // [*|*|*|1] || [*|1|*|*] if old&(mutexLocked|mutexStarving) != 0 { return false } // 尝试一次获取锁，类似 Lock() 的快速路径 // [*|0|*|0] -> [*|0|*|1] if !atomic.CompareAndSwapInt32(&m.state, old, old|mutexLocked) { return false } return true } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-08-22 "},"doc_golang/once.html":{"url":"doc_golang/once.html","title":"sync.Once","keywords":"","body":" sync.Once 代码解读 go 版本: 1.22.2 设计思想 关键结构 代码解读 sync.Once 代码解读go 版本: 1.22.2设计思想使用 Mutex 加锁，用 double check 和原子量做标记关键结构type Once struct { done atomic.Uint32 // 标记位，调用一次后标记成1 m Mutex // 互斥量 } 代码解读func (o *Once) Do(f func()) { if o.done.Load() == 0 { o.doSlow(f) } } func (o *Once) doSlow(f func()) { o.m.Lock() defer o.m.Unlock() // double check 后执行函数，再更新标记 if o.done.Load() == 0 { defer o.done.Store(1) f() } } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-08-26 "},"doc_golang/rwmutex.html":{"url":"doc_golang/rwmutex.html","title":"sync.RWMutex","keywords":"","body":" sync.RWMutex 代码解读 go 版本: 1.22.2 设计思想 关键结构 代码解读 RLock() RUnlock() TryRLock() Lock() UnLock() TryLock() sync.RWMutex 代码解读go 版本: 1.22.2设计思想RWMutex 的实现基于一个关键原则：写操作优先于读操作。这意味着如果一个写操作在等待锁，那么后续新的读操作将被阻塞，直到之前的写操作完成。这样可以防止写操作陷入“饥饿”（永远无法获得锁）。实现上，它内部使用了一个互斥锁（Mutex）用于写操作之间的互斥，并用两个信号量（readerSem 和 writerSem）来协调读和写操作。关键结构type RWMutex struct { w Mutex // 基础的互斥锁 writerSem uint32 // 写操作等待的信号量 readerSem uint32 // 读操作等待的信号量 readerCount atomic.Int32 // 当前读操作数量 readerWait atomic.Int32 // 写操作阻塞时需要等待完成的读操作数 } const rwmutexMaxReaders = 1 w (Mutex): 这是一个基础的互斥锁。它有两个主要用途：写锁之间互斥：保证同一时刻只有一个写操作能进入临界区。 实现写优先：当一个写操作到来时，它会先锁住这个 w 阻塞其他写，然后修改 readerCount 阻止读操作 writerSem 和 readerSem: 这些都是信号量，用于 goroutine 的阻塞和唤醒。writerSem: 写操作等待的信号量。一个写操作在等待时，会阻塞在这里，直到它需要等待的所有读操作都完成后，才会被唤醒。 readerSem: 读操作等待的信号量。当有一个写操作正在进行或等待时，新的读操作会阻塞在这里，直到写操作完成后才被唤醒。 readerCount: 这是一个非常巧妙的变量，它同时扮演两个角色：当前活跃的读操作数量（当值 >= 0 时）。 是否有写操作在等待的标记（当值 readerWait: 记录当一个写操作被阻塞时，它需要等待多少个正在进行的读操作完成。写操作在获取锁时，会将自己的 readerWait 设置为当时的 readerCount（正值）。每个读操作解锁时，会原子地减少 readerWait 的值。当 readerWait 减为 0 时，写操作就会被唤醒。 代码解读RLock()func (rw *RWMutex) RLock() { // 如果有写锁，readerCount 是一个很大的负值 if rw.readerCount.Add(1) RUnlock()RUnlock()func (rw *RWMutex) RUnlock() { // 快速路径(Fast Path)，如果没有写等待则直接返回，否则进入慢速路径(Slow Path) if r := rw.readerCount.Add(-1); r rUnlockSlow()func (rw *RWMutex) rUnlockSlow(r int32) { // 检查是否重复释放读锁，下列情形直接报错： // - r 为 -1，表示无写等待，读锁重复释放一次 // - r 为 -1-rwmutexMaxReaders，表示有写等待，读锁重复释放一次 if r+1 == 0 || r+1 == -rwmutexMaxReaders { fatal(\"sync: RUnlock of unlocked RWMutex\") } // 更新读等待数 if rw.readerWait.Add(-1) == 0 { // 最后一个读锁被释放后，唤醒写操作协程 runtime_Semrelease(&rw.writerSem, false, 1) } } TryRLock()func (rw *RWMutex) TryRLock() bool { for { c := rw.readerCount.Load() if c Lock()func (rw *RWMutex) Lock() { // 使用互斥锁，阻塞其他写操作 rw.w.Lock() // 更新 readerCount 为很大的负值，阻止读操作 r := rw.readerCount.Add(-rwmutexMaxReaders) + rwmutexMaxReaders // 等待前面的读操作结束 if r != 0 && rw.readerWait.Add(r) != 0 { runtime_SemacquireRWMutex(&rw.writerSem, false, 0) } } UnLock()func (rw *RWMutex) Unlock() { // 更新状态，告诉读操作此时没有写操作了 r := rw.readerCount.Add(rwmutexMaxReaders) // 检查是否重复释放写锁 if r >= rwmutexMaxReaders { fatal(\"sync: Unlock of unlocked RWMutex\") } // 唤醒读操作 for i := 0; i TryLock()func (rw *RWMutex) TryLock() bool { // 使用互斥量直接尝试加锁 if !rw.w.TryLock() { return false } // 尝试更新 readerCount 变为写锁定 if !rw.readerCount.CompareAndSwap(0, -rwmutexMaxReaders) { rw.w.Unlock() return false } return true } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-08-22 "},"doc_golang/waitgroup.html":{"url":"doc_golang/waitgroup.html","title":"sync.WaitGroup","keywords":"","body":" sync.WaitGroup 代码解读 go 版本: 1.22.2 关键结构 代码解读 Add(delta int) Done() Wait() sync.WaitGroup 代码解读go 版本: 1.22.2关键结构type WaitGroup struct { noCopy noCopy // 禁止拷贝 state atomic.Uint64 // 高32位是未完成任务数(v)，低32位是等待者数量(w) sema uint32 // 信号量，用于阻塞和唤醒 goroutine } 代码解读Add(delta int)func (wg *WaitGroup) Add(delta int) { state := wg.state.Add(uint64(delta) > 32) w := uint32(state) if v 0 && v == int32(delta) { // 防止在 Wait 期间调用 Add(正数) // 为了检测下列这种常见的错误用法： // * var wg sync.WaitGroup // * go func() { // * wg.Add(1) // 太晚了！Wait可能已经开始 // * defer wg.Done() // * // do something... // * }() // wg.Wait() // 可能在这里 panic panic(\"sync: WaitGroup misuse: Add called concurrently with Wait\") } // 只有任务处理完成(v == 0) && 有等待者(w > 0) 才需要清理和唤醒，否则退出 if v > 0 || w == 0 { return } // 运行到这里时，v == 0，w > 0，说明 Wait 已经调用过，并且任务全部完成可以开始清理 // 此时 Add 和 Wait 都不应该再被调用，所以 state 一定不会发生变化 if wg.state.Load() != state { panic(\"sync: WaitGroup misuse: Add called concurrently with Wait\") } // 清空等待者计数 wg.state.Store(0) for ; w != 0; w-- { // 唤醒所有等待者 runtime_Semrelease(&wg.sema, false, 0) } } Done()func (wg *WaitGroup) Done() { // 计数减1 wg.Add(-1) } Wait()func (wg *WaitGroup) Wait() { for { state := wg.state.Load() v := int32(state >> 32) w := uint32(state) if v == 0 { // 任务数为0，无需等待 return } // 增加等待者数量 if wg.state.CompareAndSwap(state, state+1) { runtime_Semacquire(&wg.sema) // 所有等待者被同时唤醒，此时所有任务肯定已经处理完成，并且等待者数量已经清理， if wg.state.Load() != 0 { panic(\"sync: WaitGroup is reused before previous Wait has returned\") } return } } } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-08-22 "},"doc_other/":{"url":"doc_other/","title":"其他","keywords":"","body":"简介其他分享文档Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-24 "},"doc_other/learn.html":{"url":"doc_other/learn.html","title":"学习资料整理","keywords":"","body":" 学习资料整理 FreeCodeCamp 学习资料整理FreeCodeCampFreeCodeCamp 是一个广受欢迎的在线学习平台，提供免费的编程课程和项目，帮助人们学习网页开发、数据科学和其他编程技能。该网站提供了丰富的互动编程挑战、教程以及认证课程，涵盖 HTML、CSS、JavaScript、React、Node.js 等多种技术Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-24 "},"doc_other/proxy.html":{"url":"doc_other/proxy.html","title":"wsl 科学上网","keywords":"","body":" WSL 科学上网 方案一：使用 wsl 标准模式 配置 http 代理 方案二：使用 wsl 镜像模式 额外配置 ssh 代理 WSL 科学上网方案一：使用 wsl 标准模式国内因为被墙无法正常访问 github，需要设置代理来正常访问。 本文介绍 wsl2 + ubuntu20.04 下如何设置代理以正常访问 github。配置 http 代理开启代理后，假定代理端口为 7890，在终端执行下列命令设置代理：git config --global http.proxy http://127.0.0.1:7890 git config --global https.proxy https://127.0.0.1:7890 方案二：使用 wsl 镜像模式win11 支持 wsl 设置镜像网络，可以让 wsl 共享主机网络，这种方式不需要再设置 http.proxy 和 https.proxy。设置 .wslconfig 配置后重启 wsl 即可生效[wsl2] networkingMode=mirrored localhostForwarding=true dnsTunneling=true 额外配置 ssh 代理此时已经可以使用 https 访问 github:git clone https://github.com/LRaito/books.git 但还不能使用 ssh 访问，比如下列命令不通：git clone git@github.com:LRaito/books.git 此时需要为 SSH 配置 SOCKS 代理，CFW 通常开启 SOCKS5 端口，一般使用 mixed port，可以在配置文件中看到clash 配置中可能包含 3 种端口：HTTP/HTTPS 代理端口：7890 SOCKS5 代理端口：7891 Mixed Port（混合端口）：7892（同时支持 HTTP 和 SOCKS） 编辑 ~/.ssh/config 文件，添加以下内容：Host github.com Hostname ssh.github.com User git Port 443 ProxyCommand nc -x 127.0.0.1:7890 %h %p Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-08-28 "},"doc_other/jenkins_parallel.html":{"url":"doc_other/jenkins_parallel.html","title":"Jenkins 并发构建","keywords":"","body":"Jenkins 并发构建通过 parallel 指令并发执行任务加速构建stages { stage('x86_64') { environment { GOPROXY = 'https://goproxy.cn,direct' } stages { stage('init'){ steps { script { sh \"go env\" sh \"go mod tidy\" } } } stage('build') { steps { script{ def stepsForParallel = [:] String[] apps = [\"app1\", \"app2\", \"app3\"] apps.each{ app -> stepsForParallel[app] = { stage(app) { sh \"make build -C app/${app}\" } } } parallel stepsForParallel } } } } } } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-03-24 "},"doc_other/redis_sentinel.html":{"url":"doc_other/redis_sentinel.html","title":"Redis 哨兵模式","keywords":"","body":" Redis Sentinel 哨兵模式 架构 快速部署 文件结构 docker-compose.yaml sentinel.conf 故障转移测试 常用命令 查看 master 状态 查看 slave 状态 查看 sentinel 维护的 master 状态 根据名称查 master 地址 查看 sentinel 状态 客户端 demo 常见问题 1. Failed to resolve hostname 'redis-master' 2. Could not rename tmp config file (Device or resource busy) 3. 手动停止 redis-mater 服务故障转移不生效 Redis Sentinel 哨兵模式架构┌────────────────────────────────────────────────────┐ │ Sentinel │ │ │ │ Sentinel-1 Sentinel-2 Sentinel-3 │ └────────────────────────────────────────────────────┘ ▲ | ▼ ┌─────────────────────────────────────────────────────┐ │ Redis │ │ │ │ Master Slave-1 Slave-2 │ └─────────────────────────────────────────────────────┘ 快速部署文件结构redis-sentinel ├── docker-compose.yml └── config ├── sentinel-1 │ └── sentinel.conf ├── sentinel-2 │ └── sentinel.conf └── sentinel-3 │ └── sentinel.conf └── sentinel.conf docker-compose.yamlservices: redis-master: image: redis:6.2 container_name: redis-master command: redis-server ports: - 6380:6379 redis-slave-1: image: redis:6.2 container_name: redis-slave-1 command: redis-server --slaveof redis-master 6379 ports: - 6381:6379 redis-slave-2: image: redis:6.2 container_name: redis-slave-2 command: redis-server --slaveof redis-master 6379 ports: - 6382:6379 redis-sentinel-1: image: redis:6.2 container_name: redis-sentinel-1 command: redis-sentinel /etc/redis/sentinel.conf volumes: - ./config/sentinel-1:/etc/redis ports: - 26379:26379 redis-sentinel-2: image: redis:6.2 container_name: redis-sentinel-2 command: redis-sentinel /etc/redis/sentinel.conf volumes: - ./config/sentinel-2:/etc/redis ports: - 26380:26379 redis-sentinel-3: image: redis:6.2 container_name: redis-sentinel-3 command: redis-sentinel /etc/redis/sentinel.conf volumes: - ./config/sentinel-3:/etc/redis ports: - 26381:26379 sentinel.confport 26379 dir \"/tmp\" sentinel resolve-hostnames yes sentinel monitor mymaster redis-master 6379 2 sentinel down-after-milliseconds mymaster 5000 sentinel failover-timeout mymaster 30000 sentinel deny-scripts-reconfig yes 故障转移测试# 触发故障转移 redis-cli -p 26379 sentinel failover mymaster # 查看 master 节点地址更新 redis-cli -p 26379 sentinel get-master-addr-by-name mymaster # master 可读写，slave 只读，可以写入数据测试 master 节点更新 redis-cli -p 6380 set key value 常用命令查看 master 状态redis-cli -p 6380 info replication # Replication role:master connected_slaves:2 slave0:ip=172.31.0.4,port=6379,state=online,offset=37130,lag=0 slave1:ip=172.31.0.6,port=6379,state=online,offset=37130,lag=0 master_failover_state:no-failover master_replid:7091597e5f925bfe9865272bfab57b3d0929c87c master_replid2:0000000000000000000000000000000000000000 master_repl_offset:37130 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:37130 查看 slave 状态redis-cli -p 6381 info replication # Replication role:slave master_host:redis-master master_port:6379 master_link_status:up master_last_io_seconds_ago:0 master_sync_in_progress:0 slave_read_repl_offset:47865 slave_repl_offset:47865 slave_priority:100 slave_read_only:1 replica_announced:1 connected_slaves:0 master_failover_state:no-failover master_replid:7091597e5f925bfe9865272bfab57b3d0929c87c master_replid2:0000000000000000000000000000000000000000 master_repl_offset:47865 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:47865 查看 sentinel 维护的 master 状态redis-cli -p 26379 sentinel master mymaster 1) \"name\" 2) \"mymaster\" 3) \"ip\" 4) \"172.30.0.2\" 5) \"port\" 6) \"6379\" 7) \"runid\" 8) \"13d01c0efea404e842e294749edf256a6d14865c\" 9) \"flags\" 10) \"master\" 11) \"link-pending-commands\" 12) \"0\" 13) \"link-refcount\" 14) \"1\" 15) \"last-ping-sent\" 16) \"0\" 17) \"last-ok-ping-reply\" 18) \"147\" 19) \"last-ping-reply\" 20) \"147\" 21) \"down-after-milliseconds\" 22) \"5000\" 23) \"info-refresh\" 24) \"4182\" 25) \"role-reported\" 26) \"master\" 27) \"role-reported-time\" 28) \"1208691\" 29) \"config-epoch\" 30) \"0\" 31) \"num-slaves\" 32) \"2\" 33) \"num-other-sentinels\" 34) \"2\" 35) \"quorum\" 36) \"2\" 37) \"failover-timeout\" 38) \"30000\" 39) \"parallel-syncs\" 40) \"1\" 根据名称查 master 地址redis-cli -p 26379 sentinel get-master-addr-by-name mymaster 查看 sentinel 状态redis-cli -p 26379 info sentinel # Sentinel sentinel_masters:1 sentinel_tilt:0 sentinel_running_scripts:0 sentinel_scripts_queue_length:0 sentinel_simulate_failure_flags:0 master0:name=mymaster,status=ok,address=172.31.0.7:6379,slaves=2,sentinels=3 客户端 demopackage main import ( \"context\" \"fmt\" \"time\" \"github.com/redis/go-redis/v9\" ) func main() { // 哨兵模式配置 sentinelOptions := &redis.FailoverOptions{ MasterName: \"mymaster\", // 主节点名称，在哨兵配置中指定 SentinelAddrs: []string{ // 哨兵节点地址列表 \"redis-sentinel-1:26379\", \"redis-sentinel-2:26379\", \"redis-sentinel-3:26379\", }, MaxRetries: 3, // 最大重试次数 MinRetryBackoff: 100 * time.Millisecond, // 最小重试间隔 MaxRetryBackoff: 1 * time.Second, // 最大重试间隔 DialTimeout: 5 * time.Second, // 连接超时 ReadTimeout: 5 * time.Second, // 读取超时 WriteTimeout: 5 * time.Second, // 写入超时 PoolSize: 10, // 连接池大小 } // 创建客户端 client := redis.NewFailoverClient(sentinelOptions) // 测试连接 ctx := context.Background() _, err := client.Ping(ctx).Result() if err != nil { panic(err) } for { time.Sleep(time.Second * 3) err = client.Set(ctx, \"test_key\", \"test_value\", 10*time.Minute).Err() if err == nil { fmt.Println(\"write ok\") } _, err := client.Get(ctx, \"test_key\").Result() if err == redis.Nil { fmt.Println(\"key not exist\") } else if err != nil { fmt.Println(\"read ok\") } else { fmt.Println(\"read err\") } } } 常见问题1. Failed to resolve hostname 'redis-master'sentinel 默认不开启 hostname 解析，需要增加配置: sentinel resolve-hostnames yes2. Could not rename tmp config file (Device or resource busy)不要直接挂载 sentinel.confg 配置文件，挂载目录volumes: - ./config/sentinel:/etc/redis 3. 手动停止 redis-mater 服务故障转移不生效报错 redis-master 无法解析，猜测可以设置成 IP 或者使用 DNS 服务来避免Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-08-28 "},"doc_design_pattern/":{"url":"doc_design_pattern/","title":"设计模式","keywords":"","body":" 设计模式 golang 版本 目录 参考 设计模式 golang 版本目录创建型模式工厂方法 Factory Method 抽象工厂 Abstract Factory 生成器 Builder 原型 Prototype 单例 Singleton 结构型模式适配器 Adapter 桥接 Bridge 组合 Composite 装饰 Decorator 外观 Fecade 享元 Flyweight 代理 Proxy 行为模式责任链 Chain of Responsobility 命令 Command 迭代器 Iterator 中介者 Mediator 备忘录 Memento 观察者 Observer 状态 State 策略 Strategy 模板方法 Template Method 访问者 Visitor 参考https://refactoringguru.cn/design-patterns Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-09-22 "},"doc_design_pattern/factory_method.html":{"url":"doc_design_pattern/factory_method.html","title":"工厂方法","keywords":"","body":" 工厂方法 Factory Method 示例 iGun.go: 产品接口 gun.go: 具体产品 ak47.go: 具体产品 musket.go: 具体产品 gunFactory.go: 工厂 main.go: 客户端代码 工厂方法 Factory Method工厂方法模式是一种创建型设计模式， 其在父类中提供一个创建对象的方法， 允许子类决定实例化对象的类型。由于 Go 中缺少类和继承等 OOP 特性，所以无法使用 Go 来实现经典的工厂方法模式。不过我们仍然能实现模式的基础版本，即简单工厂。示例创建一个名为 i­Gun 的接口， 其中将定义一支枪所需具备的所有方法 然后是实现了 iGun 接口的 gun枪支结构体类型。两种具体的枪支：ak47 与 musket 火枪，两者都嵌入了枪支结构体， 且间接实现了所有的 i­Gun方法 gun­Factory 枪支工厂结构体将发挥工厂的作用，即通过传入参数构建所需类型的枪支 iGun.go: 产品接口package main type IGun interface { setName(name string) setPower(power int) getName() string getPower() int } gun.go: 具体产品package main type Gun struct { name string power int } func (g *Gun) setName(name string) { g.name = name } func (g *Gun) getName() string { return g.name } func (g *Gun) setPower(power int) { g.power = power } func (g *Gun) getPower() int { return g.power } ak47.go: 具体产品package main type Ak47 struct { Gun } func newAk47() IGun { return &Ak47{ Gun: Gun{ name: \"AK47 gun\", power: 4, }, } } musket.go: 具体产品package main type musket struct { Gun } func newMusket() IGun { return &musket{ Gun: Gun{ name: \"Musket gun\", power: 1, }, } } gunFactory.go: 工厂package main import \"fmt\" func getGun(gunType string) (IGun, error) { if gunType == \"ak47\" { return newAk47(), nil } if gunType == \"musket\" { return newMusket(), nil } return nil, fmt.Errorf(\"Wrong gun type passed\") } main.go: 客户端代码package main import \"fmt\" func main() { ak47, _ := getGun(\"ak47\") musket, _ := getGun(\"musket\") printDetails(ak47) printDetails(musket) } func printDetails(g IGun) { fmt.Printf(\"Gun: %s\", g.getName()) fmt.Println() fmt.Printf(\"Power: %d\", g.getPower()) fmt.Println() } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-09-22 "},"doc_design_pattern/abstract_factory.html":{"url":"doc_design_pattern/abstract_factory.html","title":"抽象工厂","keywords":"","body":" 抽象工厂 Abstract Factory 示例 iSportsFactory.go: 抽象工厂接口 adidas.go: 具体工厂 nike.go: 具体工厂 iShoe.go: 抽象产品 adidasShoe.go: 具体产品 nikeShoe.go: 具体产品 iShirt.go: 抽象产品 adidasShirt.go: 具体产品 nikeShirt.go: 具体产品 main.go: 客户端代码 抽象工厂 Abstract Factory抽象工厂模式是一种创建型设计模式， 它能创建一系列相关的对象， 而无需指定其具体类。示例让我们假设一下，如果你想要购买一组运动装备，比如一双鞋与一件衬衫这样由两种不同产品组合而成的套装。相信你会想去购买同一品牌的商品，这样商品之间能够互相搭配起来。如果我们把这样的行为转换成代码的话，帮助我们创建此类产品组的工具就是抽象工厂，便于产品之间能够相互匹配。iSportsFactory.go: 抽象工厂接口package main import \"fmt\" type ISportsFactory interface { makeShoe() IShoe makeShirt() IShirt } func GetSportsFactory(brand string) (ISportsFactory, error) { if brand == \"adidas\" { return &Adidas{}, nil } if brand == \"nike\" { return &Nike{}, nil } return nil, fmt.Errorf(\"Wrong brand type passed\") } adidas.go: 具体工厂package main type Adidas struct { } func (a *Adidas) makeShoe() IShoe { return &AdidasShoe{ Shoe: Shoe{ logo: \"adidas\", size: 14, }, } } func (a *Adidas) makeShirt() IShirt { return &AdidasShirt{ Shirt: Shirt{ logo: \"adidas\", size: 14, }, } } nike.go: 具体工厂package main type Nike struct { } func (n *Nike) makeShoe() IShoe { return &NikeShoe{ Shoe: Shoe{ logo: \"nike\", size: 14, }, } } func (n *Nike) makeShirt() IShirt { return &NikeShirt{ Shirt: Shirt{ logo: \"nike\", size: 14, }, } } iShoe.go: 抽象产品package main type IShoe interface { setLogo(logo string) setSize(size int) getLogo() string getSize() int } type Shoe struct { logo string size int } func (s *Shoe) setLogo(logo string) { s.logo = logo } func (s *Shoe) getLogo() string { return s.logo } func (s *Shoe) setSize(size int) { s.size = size } func (s *Shoe) getSize() int { return s.size } adidasShoe.go: 具体产品package main type AdidasShoe struct { Shoe } nikeShoe.go: 具体产品package main type NikeShoe struct { Shoe } iShirt.go: 抽象产品package main type IShirt interface { setLogo(logo string) setSize(size int) getLogo() string getSize() int } type Shirt struct { logo string size int } func (s *Shirt) setLogo(logo string) { s.logo = logo } func (s *Shirt) getLogo() string { return s.logo } func (s *Shirt) setSize(size int) { s.size = size } func (s *Shirt) getSize() int { return s.size } adidasShirt.go: 具体产品package main type AdidasShirt struct { Shirt } nikeShirt.go: 具体产品package main type NikeShirt struct { Shirt } main.go: 客户端代码package main import \"fmt\" func main() { adidasFactory, _ := GetSportsFactory(\"adidas\") nikeFactory, _ := GetSportsFactory(\"nike\") nikeShoe := nikeFactory.makeShoe() nikeShirt := nikeFactory.makeShirt() adidasShoe := adidasFactory.makeShoe() adidasShirt := adidasFactory.makeShirt() printShoeDetails(nikeShoe) printShirtDetails(nikeShirt) printShoeDetails(adidasShoe) printShirtDetails(adidasShirt) } func printShoeDetails(s IShoe) { fmt.Printf(\"Logo: %s\", s.getLogo()) fmt.Println() fmt.Printf(\"Size: %d\", s.getSize()) fmt.Println() } func printShirtDetails(s IShirt) { fmt.Printf(\"Logo: %s\", s.getLogo()) fmt.Println() fmt.Printf(\"Size: %d\", s.getSize()) fmt.Println() } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-09-22 "},"doc_design_pattern/builder.html":{"url":"doc_design_pattern/builder.html","title":"生成器","keywords":"","body":" 生成器 Builder 示例 iBuilder.go: 生成器接口 normalBuilder.go: 具体生成器 iglooBuilder.go: 具体生成器 house.go: 产品 director.go: 主管 main.go: 客户端代码 生成器 Builder生成器是一种创建型设计模式，使你能够分步骤创建复杂对象。示例当所需产品较为复杂且需要多个步骤才能完成时，也可以使用生成器模式。在这种情况下，使用多个构造方法比仅仅使用一个复杂可怕的构造函数更简单。分为多个步骤进行构建的潜在问题是，构建不完整的和不稳定的产品可能会被暴露给客户端。生成器模式能够在产品完成构建之前使其处于私密状态。在下方的代码中，我们可以看到 igloo­Builder冰屋生成器与 normal­Builder普通房屋生成器可建造不同类型房屋，即 igloo 冰屋和 normal­House 普通房屋 。每种房屋类型的建造步骤都是相同的。主管（可选）结构体可对建造过程进行组织。iBuilder.go: 生成器接口package main type IBuilder interface { setWindowType() setDoorType() setNumFloor() getHouse() House } func getBuilder(builderType string) IBuilder { if builderType == \"normal\" { return newNormalBuilder() } if builderType == \"igloo\" { return newIglooBuilder() } return nil } normalBuilder.go: 具体生成器package main type NormalBuilder struct { windowType string doorType string floor int } func newNormalBuilder() *NormalBuilder { return &NormalBuilder{} } func (b *NormalBuilder) setWindowType() { b.windowType = \"Wooden Window\" } func (b *NormalBuilder) setDoorType() { b.doorType = \"Wooden Door\" } func (b *NormalBuilder) setNumFloor() { b.floor = 2 } func (b *NormalBuilder) getHouse() House { return House{ doorType: b.doorType, windowType: b.windowType, floor: b.floor, } } iglooBuilder.go: 具体生成器package main type IglooBuilder struct { windowType string doorType string floor int } func newIglooBuilder() *IglooBuilder { return &IglooBuilder{} } func (b *IglooBuilder) setWindowType() { b.windowType = \"Snow Window\" } func (b *IglooBuilder) setDoorType() { b.doorType = \"Snow Door\" } func (b *IglooBuilder) setNumFloor() { b.floor = 1 } func (b *IglooBuilder) getHouse() House { return House{ doorType: b.doorType, windowType: b.windowType, floor: b.floor, } } house.go: 产品package main type House struct { windowType string doorType string floor int } director.go: 主管package main type Director struct { builder IBuilder } func newDirector(b IBuilder) *Director { return &Director{ builder: b, } } func (d *Director) setBuilder(b IBuilder) { d.builder = b } func (d *Director) buildHouse() House { d.builder.setDoorType() d.builder.setWindowType() d.builder.setNumFloor() return d.builder.getHouse() } main.go: 客户端代码package main import \"fmt\" func main() { normalBuilder := getBuilder(\"normal\") iglooBuilder := getBuilder(\"igloo\") director := newDirector(normalBuilder) normalHouse := director.buildHouse() fmt.Printf(\"Normal House Door Type: %s\\n\", normalHouse.doorType) fmt.Printf(\"Normal House Window Type: %s\\n\", normalHouse.windowType) fmt.Printf(\"Normal House Num Floor: %d\\n\", normalHouse.floor) director.setBuilder(iglooBuilder) iglooHouse := director.buildHouse() fmt.Printf(\"\\nIgloo House Door Type: %s\\n\", iglooHouse.doorType) fmt.Printf(\"Igloo House Window Type: %s\\n\", iglooHouse.windowType) fmt.Printf(\"Igloo House Num Floor: %d\\n\", iglooHouse.floor) } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-09-22 "},"doc_design_pattern/prototype.html":{"url":"doc_design_pattern/prototype.html","title":"原型","keywords":"","body":" 原型 Prototype 示例 inode.go: 原型接口 file.go: 具体原型 folder.go: 具体原型 main.go: 客户端代码 原型 Prototype原型是一种创建型设计模式，使你能够复制对象，甚至是复杂对象，而又无需使代码依赖它们所属的类。示例让我们尝试通过基于操作系统文件系统的示例来理解原型模式。操作系统的文件系统是递归的：文件夹中包含文件和文件夹，其中又包含文件和文件夹，以此类推。每个文件和文件夹都可用一个 inode 接口来表示。​ inode 接口中同样也有 clone 克隆功能。file 文件和 folder 文件夹结构体都实现了 print 打印和 clone 方法，因为它们都是 inode 类型。同时，注意 file 和 folder 中的 clone 方法。这两者的 clone 方法都会返回相应文件或文件夹的副本。同时在克隆过程中，我们会在其名称后面添加 “_clone” 字样。inode.go: 原型接口package main type Inode interface { print(string) clone() Inode } file.go: 具体原型package main import \"fmt\" type File struct { name string } func (f *File) print(indentation string) { fmt.Println(indentation + f.name) } func (f *File) clone() Inode { return &File{name: f.name + \"_clone\"} } folder.go: 具体原型package main import \"fmt\" type Folder struct { children []Inode name string } func (f *Folder) print(indentation string) { fmt.Println(indentation + f.name) for _, i := range f.children { i.print(indentation + indentation) } } func (f *Folder) clone() Inode { cloneFolder := &Folder{name: f.name + \"_clone\"} var tempChildren []Inode for _, i := range f.children { copy := i.clone() tempChildren = append(tempChildren, copy) } cloneFolder.children = tempChildren return cloneFolder } main.go: 客户端代码package main import \"fmt\" func main() { file1 := &File{name: \"File1\"} file2 := &File{name: \"File2\"} file3 := &File{name: \"File3\"} folder1 := &Folder{ children: []Inode{file1}, name: \"Folder1\", } folder2 := &Folder{ children: []Inode{folder1, file2, file3}, name: \"Folder2\", } fmt.Println(\"\\nPrinting hierarchy for Folder2\") folder2.print(\" \") cloneFolder := folder2.clone() fmt.Println(\"\\nPrinting hierarchy for clone Folder\") cloneFolder.print(\" \") } output.txt: 执行结果Printing hierarchy for Folder2 Folder2 Folder1 File1 File2 File3 Printing hierarchy for clone Folder Folder2_clone Folder1_clone File1_clone File2_clone File3_clone Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-09-22 "},"doc_design_pattern/singleton.html":{"url":"doc_design_pattern/singleton.html","title":"单例","keywords":"","body":" 单例 Singleton 示例一 示例二 示例三 单例 Singleton单例模式是一种创建型设计模式， 让你能够保证一个类只有一个实例， 并提供一个访问该实例的全局节点。示例一先不加锁快速判断返回提高性能 加锁后 double check 保证并发安全 package main import ( \"fmt\" \"sync\" ) var lock = &sync.Mutex{} type single struct { } var singleInstance *single func getInstance() *single { // double check if singleInstance == nil { lock.Lock() defer lock.Unlock() if singleInstance == nil { fmt.Println(\"Creating single instance now.\") singleInstance = &single{} } else { fmt.Println(\"Single instance already created.\") } } else { fmt.Println(\"Single instance already created.\") } return singleInstance } 示例二init 函数会在包中的每个文件调用一次，可以做单例初始化动作 func init () {} 示例三使用 sync.Once 实现单例，实际底层实现是原子量加互斥锁 package main import ( \"fmt\" \"sync\" ) var once sync.Once type single struct { } var singleInstance *single func getInstance() *single { if singleInstance == nil { once.Do( func() { fmt.Println(\"Creating single instance now.\") singleInstance = &single{} }) } else { fmt.Println(\"Single instance already created.\") } return singleInstance } Copyright ©ZhangFeng all right reserved，powered by Gitbook 2025-09-22 "}}